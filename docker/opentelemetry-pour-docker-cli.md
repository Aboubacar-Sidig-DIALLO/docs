# ğŸ“Š OpenTelemetry pour Docker CLI

### ğŸ”¹ PrÃ©requis

* **Docker Engine â‰¥ 26.1.0**
* Docker CLI installÃ©

Ã€ partir de cette version, **le CLI Docker peut Ã©mettre des mÃ©triques OpenTelemetry** sur les commandes que tu exÃ©cutes (`docker run`, `docker build`, etc.).

***

### ğŸ”¹ FonctionnalitÃ©

* Par dÃ©faut : **dÃ©sactivÃ©e** âœ…
* Objectif : envoyer des mÃ©triques vers un **collecteur OpenTelemetry** (ex. Prometheus, Jaeger, Grafana Tempo, OTEL Collector).
* Permet :
  * de suivre lâ€™usage du CLI Docker,
  * de voir combien de fois certaines commandes sont appelÃ©es,
  * de monitorer tes habitudes et flux dâ€™utilisation Docker.

***

### ğŸ”¹ Comment activer lâ€™export

Tu dois configurer **lâ€™adresse du collecteur**.\
Exemple (Linux/macOS) :

```bash
export DOCKER_CLI_METRICS="otel:http://localhost:4318"
```

ğŸ‘‰ Ici :

* `otel:` â†’ dit au CLI dâ€™utiliser OpenTelemetry,
* `http://localhost:4318` â†’ correspond au port par dÃ©faut de lâ€™**OTEL Collector (OTLP/HTTP exporter)**.

***

### ğŸ”¹ VÃ©rification

Lance une commande Docker, par exemple :

```bash
docker ps
```

Puis vÃ©rifie dans ton collecteur OpenTelemetry que des mÃ©triques arrivent (ex. `otelcol`, Grafana Agent, etc.).

***

### ğŸ”¹ Ce que Ã§a rapporte comme mÃ©triques

Les mÃ©triques typiques envoyÃ©es incluent :

* **Nom de la commande** (`docker build`, `docker run`, etc.)
* **SuccÃ¨s ou Ã©chec** de la commande
* **DurÃ©e dâ€™exÃ©cution**
* **Arguments principaux** (pas tout, mais de quoi profiler)

***

### âš ï¸ Attention

* **Opt-in uniquement** â†’ rien nâ€™est envoyÃ© sans ta configuration.
* **Tu choisis ton endpoint** â†’ tes donnÃ©es ne partent pas ailleurs.
* **Usage recommandÃ©** â†’ pour observabilitÃ© interne, intÃ©gration CI/CD, analytics dâ€™usage Docker.

## ğŸ” Quâ€™est-ce quâ€™OpenTelemetry (OTel) ?

**OpenTelemetry (OTel)** est un **framework open source** qui sert Ã  collecter, gÃ©nÃ©rer et gÃ©rer des donnÃ©es dâ€™observabilitÃ©.\
Ces donnÃ©es sont de trois types :

* **Traces** ğŸŸ£ â†’ suivent le parcours dâ€™une requÃªte ou dâ€™un Ã©vÃ©nement Ã  travers diffÃ©rents services (utile pour le tracing distribuÃ©).
* **MÃ©triques** ğŸŸ¢ â†’ valeurs chiffrÃ©es comme CPU, mÃ©moire, latence, nombre de requÃªtes, erreurs, etc.
* **Logs** ğŸ”µ â†’ messages textuels gÃ©nÃ©rÃ©s par les applications ou systÃ¨mes.

***

### ğŸ¯ Objectifs dâ€™OpenTelemetry

1. **Standardisation** :
   * Fournir un langage et un protocole communs pour la collecte de donnÃ©es.
   * Ã‰viter de dÃ©pendre dâ€™un outil ou dâ€™un fournisseur spÃ©cifique.
2. **InteropÃ©rabilitÃ©** :
   * Fonctionne avec **beaucoup dâ€™outils de monitoring et observabilitÃ©** comme Prometheus, Grafana, Jaeger, Elastic, Datadog, New Relic, etc.
3. **Instrumentation facile** :
   * Fournit des **librairies prÃªtes Ã  lâ€™emploi** pour diffÃ©rents langages (Java, Go, Python, JS, etc.).
   * Permet dâ€™ajouter de la tÃ©lÃ©mÃ©trie sans rÃ©Ã©crire ton application.

***

### ğŸ› ï¸ Dans le contexte Docker CLI

Avec **le support OpenTelemetry**, le **CLI Docker peut Ã©mettre des mÃ©triques** (Ã©vÃ©nements, commandes exÃ©cutÃ©es, durÃ©e, statut, etc.) selon le standard OTel.\
ğŸ‘‰ Ã‡a veut dire que tu peux suivre et analyser **comment tes commandes Docker sont utilisÃ©es**, en envoyant ces infos vers un collecteur OTel ou une plateforme dâ€™observabilitÃ©.

***

### ğŸ“Š Exemple de flux OTel

1. **Application ou CLI** gÃ©nÃ¨re les donnÃ©es dâ€™observabilitÃ© (Docker CLI dans ton cas).
2. Ces donnÃ©es passent via un **OTel Collector**.
3. Le collecteur exporte vers des systÃ¨mes comme **Prometheus, Jaeger ou Grafana** pour les visualiser.

***

âœ… En rÃ©sumÃ© :\
**OpenTelemetry = le standard universel et open source pour collecter traces, mÃ©triques et logs, indÃ©pendamment du fournisseur dâ€™outils.**

## âš™ï¸ Fonctionnement : Docker CLI + OpenTelemetry

1. **Par dÃ©faut â†’ Pas de tÃ©lÃ©mÃ©trie**
   * Quand tu installes et utilises Docker CLI, il **nâ€™envoie aucune donnÃ©e**.
   * Câ€™est totalement **opt-in** â†’ tu dois activer manuellement la tÃ©lÃ©mÃ©trie.

***

2.  **Activer lâ€™export OpenTelemetry**

    * Tu dÃ©finis une **variable dâ€™environnement** :

    ```bash
    export DOCKER_CLI_OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
    ```

    Ici :

    * `DOCKER_CLI_OTEL_EXPORTER_OTLP_ENDPOINT` â†’ indique oÃ¹ envoyer les mÃ©triques.
    * `http://localhost:4317` â†’ correspond Ã  lâ€™adresse dâ€™un **OTel Collector** qui Ã©coute en local (port par dÃ©faut : 4317 pour gRPC, 4318 pour HTTP).

***

3. **Docker CLI gÃ©nÃ¨re la tÃ©lÃ©mÃ©trie**
   * Chaque fois que tu tapes une commande `docker run`, `docker build`, etc. â†’\
     des **mÃ©triques** (durÃ©e, statut, type de commande) sont crÃ©Ã©es.
   * Ces mÃ©triques suivent le **format OTel (OTLP)**.

***

4.  **Le rÃ´le de lâ€™OpenTelemetry Collector** ğŸ› ï¸

    * Le **collector** est un composant central qui :
      * **reÃ§oit** les donnÃ©es de tÃ©lÃ©mÃ©trie (depuis Docker CLI, ton app, etc.),
      * peut **les transformer/filtrer** (ex. : garder seulement certaines mÃ©triques),
      * puis les **exporte vers un backend**.

    Exemple de backends possibles :

    * **Prometheus / InfluxDB** â†’ stockage de mÃ©triques.
    * **Jaeger / Zipkin** â†’ visualisation des traces.
    * **Grafana** â†’ dashboards interactifs.

***

5. **Visualisation des donnÃ©es** ğŸ“Š
   * Si ton backend le permet (ex. Grafana branchÃ© sur Prometheus), tu peux avoir :
     * ğŸ“ˆ des graphes de **durÃ©e moyenne des commandes Docker**
     * ğŸ” un suivi de la **frÃ©quence des builds/run**
     * ğŸš¨ des alertes si certaines commandes Ã©chouent souvent

***

âœ… **RÃ©sumÃ© simple :**

* Le Docker CLI **nâ€™Ã©met rien par dÃ©faut**.
* Tu actives lâ€™export en dÃ©finissant une variable dâ€™env. (`DOCKER_CLI_OTEL_EXPORTER_OTLP_ENDPOINT`).
* Les donnÃ©es vont vers un **OTel Collector**.
* Le collector envoie ces donnÃ©es vers ton backend (Prometheus, InfluxDB, Grafana, etc.) pour analyse.

## âš™ï¸ Mise en place : OpenTelemetry pour Docker CLI

### 1. PrÃ©parer les fichiers de config

ğŸ‘‰ **`compose.yaml`**

```yaml
name: cli-otel
services:
  prometheus:
    image: prom/prometheus
    command:
      - "--config.file=/etc/prometheus/prom.yml"
    ports:
      # Interface Prometheus : http://localhost:9091
      - 9091:9090
    restart: always
    volumes:
      - prom_data:/prometheus
      - ./prom.yml:/etc/prometheus/prom.yml

  otelcol:
    image: otel/opentelemetry-collector
    restart: always
    depends_on:
      - prometheus
    ports:
      - 4317:4317   # Port OTLP gRPC (oÃ¹ le Docker CLI enverra ses mÃ©triques)
    volumes:
      - ./otelcol.yml:/etc/otelcol/config.yaml

volumes:
  prom_data:
```

ğŸ‘‰ **`otelcol.yml`** (collector)

```yaml
# RÃ©ception OTLP (depuis Docker CLI)
receivers:
  otlp:
    protocols:
      grpc:
      http:

# Export vers Prometheus
exporters:
  prometheus:
    endpoint: "0.0.0.0:8889"

service:
  pipelines:
    metrics:
      receivers: [otlp]
      exporters: [prometheus]
```

ğŸ‘‰ **`prom.yml`** (Prometheus)

```yaml
scrape_configs:
  - job_name: "otel-collector"
    scrape_interval: 1s
    static_configs:
      - targets: ["otelcol:8889"]
```

***

### 2. Lancer lâ€™infra

```bash
docker compose up -d
```

Cela dÃ©marre :

* **otelcol** â†’ reÃ§oit les mÃ©triques du Docker CLI (via OTLP gRPC sur `4317`)
* **prometheus** â†’ scrape les mÃ©triques de lâ€™OTel collector (`:8889`)
* **Prometheus UI** accessible sur ğŸ‘‰ [http://localhost:9091](http://localhost:9091)

***

### 3. Activer lâ€™export OpenTelemetry dans le Docker CLI

```bash
export DOCKER_CLI_OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
```

âš ï¸ Cette variable doit Ãªtre dÃ©finie **dans ton shell avant dâ€™exÃ©cuter `docker`**.\
(Tu peux aussi lâ€™ajouter dans ton `~/.bashrc` ou `~/.zshrc` pour la rendre permanente).

***

### 4. GÃ©nÃ©rer des mÃ©triques

ExÃ©cute une commande Docker, par exemple :

```bash
docker version
```

Cela envoie une mÃ©trique au collector.

***

### 5. VÃ©rifier dans Prometheus

* Ouvre : [http://localhost:9091/graph](http://localhost:9091/graph)
* Dans le champ **Query**, tape :

```
command_time_milliseconds_total
```

Puis **Execute** â†’ tu verras les mÃ©triques des commandes Docker (temps dâ€™exÃ©cution, nombre dâ€™invocationsâ€¦).

***

âœ… **RÃ©sumÃ©** :

* Tu dÃ©marres lâ€™infra avec `docker compose up`.
* Tu exportes `DOCKER_CLI_OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317`.
* Tu lances une commande Docker.
* Tu visualises la mÃ©trique `command_time_milliseconds_total` dans Prometheus.

## ğŸ“Š MÃ©trique disponible dans Docker CLI (OpenTelemetry)

#### ğŸ”¹ Nom

`command.time`

#### ğŸ”¹ Description

Mesure le **temps dâ€™exÃ©cution** dâ€™une commande Docker (en millisecondes).

#### ğŸ”¹ Attributs associÃ©s

Chaque mÃ©trique est enrichie avec des **labels (attributs)** pour permettre une analyse plus fine :

| Attribut                | Description                                                                          |
| ----------------------- | ------------------------------------------------------------------------------------ |
| `command.name`          | Le nom de la commande exÃ©cutÃ©e (ex: `docker run`, `docker ps`, `docker build`, etc.) |
| `command.status.code`   | Le code de sortie de la commande (`0` si succÃ¨s, autre valeur si erreur)             |
| `command.stderr.isatty` | `true` si `stderr` est connectÃ© Ã  un TTY (terminal interactif), sinon `false`        |
| `command.stdin.isatty`  | `true` si `stdin` est connectÃ© Ã  un TTY                                              |
| `command.stdout.isatty` | `true` si `stdout` est connectÃ© Ã  un TTY                                             |

***

#### ğŸ”¹ Exemple concret

Si tu exÃ©cutes :

```bash
docker ps
```

Alors dans **Prometheus**, tu pourrais voir une entrÃ©e comme :

```
command_time_milliseconds_total{
  command_name="ps",
  command_status_code="0",
  command_stderr_isatty="true",
  command_stdin_isatty="false",
  command_stdout_isatty="true"
} 45
```

ğŸ‘‰ Cela veut dire :

* La commande `docker ps` a pris **45 ms** Ã  sâ€™exÃ©cuter.
* Elle sâ€™est terminÃ©e avec un **exit code = 0** (succÃ¨s).
* `stdout` et `stderr` Ã©taient reliÃ©s Ã  un terminal.

***

âš¡ Ã‡a permet ensuite de faire des **stats dâ€™usage** :

* Temps moyen dâ€™exÃ©cution par commande (`avg by(command_name)`).
* Taux dâ€™erreurs (`rate(command_time_milliseconds_total{command_status_code!="0"}[5m])`).
* Profil dâ€™utilisation (quelles commandes sont les plus utilisÃ©es).
