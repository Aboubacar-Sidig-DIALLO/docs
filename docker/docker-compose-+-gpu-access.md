# âš¡ï¸ Docker Compose + GPU Access

### âœ… PrÃ©requis

1. **Pilotes GPU installÃ©s sur lâ€™hÃ´te**
   * Pour NVIDIA â†’ NVIDIA drivers + NVIDIA Container Toolkit.
   * Pour dâ€™autres GPU (AMD, Intel), utiliser lâ€™Ã©quivalent du runtime compatible.
2. **Docker Daemon configurÃ©**\
   Le runtime NVIDIA doit Ãªtre disponible (souvent `--gpus` est activÃ© automatiquement aprÃ¨s installation du toolkit).
3. **Compose V2** (ou `docker-compose` V1 avec `runtime: nvidia`, mais V1 est obsolÃ¨te).

***

### ğŸ› ï¸ Exemple simple avec `device_requests`

Depuis Compose **V2.3+**, on utilise `device_requests` dans la section `deploy.resources` :

```yaml
services:
  gpu-app:
    image: nvidia/cuda:12.2.0-base-ubuntu22.04
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all    # ou un nombre spÃ©cifique, ex: 1
              capabilities: [gpu]
```

* `driver: nvidia` â†’ indique dâ€™utiliser le runtime NVIDIA.
* `count: all` â†’ alloue tous les GPU dispo (tu peux mettre `1`, `2`, etc.).
* `capabilities: [gpu]` â†’ indique quâ€™on veut utiliser les GPU (tu peux ajouter `utility`, `video`, `compute` selon besoins).

***

### ğŸ–¥ï¸ Exemple : allouer un seul GPU spÃ©cifique

Tu peux demander un GPU particulier via son index :

```yaml
services:
  gpu-app:
    image: nvidia/cuda:12.2.0-runtime-ubuntu22.04
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]   # GPU nÂ°0 uniquement
              capabilities: [gpu]
```

***

### ğŸ” VÃ©rifier dans le conteneur

Une fois le service lancÃ© :

```bash
docker compose up -d
docker compose exec gpu-app nvidia-smi
```

ğŸ‘‰ Si tout est bien configurÃ©, tu verras lâ€™Ã©tat de tes GPU depuis le conteneur.

***

### âš ï¸ Attention

* Le champ `deploy` est **normalement utilisÃ© pour Swarm**, mais **`docker compose` (standalone) supporte aussi `device_requests`**.
* Si tu es encore en **Compose V1**, il faut utiliser :

```yaml
services:
  gpu-app:
    image: nvidia/cuda:12.2.0-base-ubuntu22.04
    runtime: nvidia
```

Mais â†’ **Compose V1 est obsolÃ¨te**, passe Ã  V2.

## âš¡ Utiliser les GPU avec Docker Compose

### ğŸ”‘ RÃ¨gles importantes

* Les GPU sâ€™ajoutent via la section `deploy.resources.reservations.devices`.
* **`capabilities` est obligatoire** â†’ au minimum `[gpu]`.
* Tu dois choisir **soit `count`** (nombre de GPU Ã  rÃ©server), **soit `device_ids`** (cibler un GPU prÃ©cis). Pas les deux en mÃªme temps.
* `driver: nvidia` â†’ requis pour activer le runtime NVIDIA.
* `options` â†’ permet dâ€™ajouter des rÃ©glages spÃ©cifiques au pilote (cas avancÃ©s).

***

### âœ… Exemple 1 : Service avec 1 GPU

```yaml
services:
  test:
    image: nvidia/cuda:12.9.0-base-ubuntu22.04
    command: nvidia-smi
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

ğŸ‘‰ Lancer avec :

```bash
docker compose up
```

â¡ï¸ Le conteneur exÃ©cutera `nvidia-smi` et affichera les informations de ton GPU.

***

### âœ… Exemple 2 : Cibler un GPU prÃ©cis

```yaml
services:
  gpu-service:
    image: nvidia/cuda:12.9.0-runtime-ubuntu22.04
    command: nvidia-smi
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["2"]   # Utilise uniquement le GPU nÂ°2
              capabilities: [gpu]
```

***

### âœ… Exemple 3 : Utiliser tous les GPU disponibles

```yaml
services:
  gpu-all:
    image: nvidia/cuda:12.9.0-base-ubuntu22.04
    command: nvidia-smi
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
```

***

### ğŸ” VÃ©rifier les GPU disponibles

Sur ta machine hÃ´te (avant Compose) :

```bash
nvidia-smi
```

ğŸ‘‰ Tu verras la liste des GPU avec leur **ID** (0,1,2,3, â€¦).\
Ces IDs peuvent Ãªtre utilisÃ©s avec `device_ids`.

***

### âš ï¸ Erreurs courantes

* âŒ Oublier `capabilities: [gpu]` â†’ erreur au dÃ©ploiement.
* âŒ Utiliser `count` **et** `device_ids` en mÃªme temps â†’ erreur.
* âŒ Demander plus de GPU que la machine nâ€™en possÃ¨de â†’ erreur immÃ©diate.

## ğŸ¯ AccÃ¨s Ã  des GPU spÃ©cifiques avec Docker Compose

Si ta machine possÃ¨de plusieurs GPU (ex. 0, 1, 2, 3), tu peux limiter un service pour quâ€™il nâ€™utilise **que certains dâ€™entre eux**.

ğŸ‘‰ Exemple : donner uniquement accÃ¨s Ã  **GPU-0 et GPU-3** :

```yaml
services:
  test:
    image: tensorflow/tensorflow:latest-gpu
    command: python -c "import tensorflow as tf; print(tf.test.gpu_device_name())"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '3']
              capabilities: [gpu]
```

***

### ğŸ” Explication

* `driver: nvidia` â†’ indispensable pour utiliser le runtime NVIDIA.
* `device_ids: ['0', '3']` â†’ seuls les GPU **0 et 3** seront visibles par le conteneur.
* `capabilities: [gpu]` â†’ obligatoire (sinon Docker Compose renvoie une erreur).
* `command: ...` â†’ ici on vÃ©rifie dans TensorFlow que le GPU est bien accessible.

***

### âœ… VÃ©rification

Avant de lancer ton service, regarde tes GPU disponibles sur lâ€™hÃ´te avec :

```bash
nvidia-smi
```

Tu verras une liste comme :

```
+-----------------------------------------------------------------------------+
| GPU   Name                 Persistence-M| Bus-Id        Disp.A | Volatile ECC |
|  0   Tesla T4                        On | 00000000:00:1B.0 Off | 0            |
|  1   Tesla T4                        On | 00000000:00:1C.0 Off | 0            |
|  2   Tesla T4                        On | 00000000:00:1D.0 Off | 0            |
|  3   Tesla T4                        On | 00000000:00:1E.0 Off | 0            |
+-----------------------------------------------------------------------------+
```

ğŸ‘‰ Ici, si tu choisis `['0','3']`, seul le **premier et dernier GPU** seront visibles dans le conteneur.

***

### âš ï¸ Attention

* Tu ne peux **pas mÃ©langer `count` et `device_ids`** dans la mÃªme config.
* Si tu mets un ID qui nâ€™existe pas (ex. `5` alors que tu nâ€™as que 4 GPU), Docker retournera une erreur.
* Si tu ne prÃ©cises pas `device_ids`, **tous les GPU disponibles** seront exposÃ©s par dÃ©faut.
