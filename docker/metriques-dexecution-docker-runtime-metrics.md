# ğŸ“Š MÃ©triques dâ€™exÃ©cution Docker (Runtime Metrics)

### ğŸ”¹ 1. `docker stats`

La commande `docker stats` permet de **surveiller en temps rÃ©el** la consommation des conteneurs.\
Elle affiche :

* **CPU %** â†’ pourcentage dâ€™utilisation CPU par conteneur
* **MEM USAGE / LIMIT** â†’ mÃ©moire utilisÃ©e / limite mÃ©moire
* **MEM %** â†’ pourcentage de mÃ©moire utilisÃ©e par rapport Ã  la limite
* **NET I/O** â†’ trafic rÃ©seau entrant/sortant
* **BLOCK I/O** â†’ lecture/Ã©criture disque (I/O bloc)

ğŸ‘‰ Exemple :

```bash
docker stats redis1 redis2
```

RÃ©sultat :

```
CONTAINER   CPU %   MEM USAGE / LIMIT   MEM %   NET I/O        BLOCK I/O
redis1      0.07%   796 KB / 64 MB      1.21%   788 B / 648 B  3.568 MB / 512 KB
redis2      0.07%   2.7 MB / 64 MB      4.29%   1.2 KB / 648 B 12.4 MB / 0 B
```

ğŸ‘‰ TrÃ¨s pratique pour un **suivi en direct**, comme `top` pour les processus.

***

### ğŸ”¹ 2. Cgroups (Control Groups)

Sous Linux, les **cgroups** sont utilisÃ©s pour :

* **Limiter** les ressources (CPU, mÃ©moire, disque, rÃ©seau)
* **Surveiller** la consommation
* **Isoler** les processus dans des hiÃ©rarchies

ğŸ“Œ Les cgroups exposent leurs mÃ©triques via un **pseudo-systÃ¨me de fichiers** :

```
/sys/fs/cgroup/
```

On y trouve plusieurs sous-dossiers : `cpu`, `memory`, `blkio`, etc.

ğŸ‘‰ Pour voir oÃ¹ les cgroups sont montÃ©s :

```bash
grep cgroup /proc/mounts
```

***

### ğŸ”¹ 3. cgroup v1 vs v2

* **cgroup v1** : hiÃ©rarchies sÃ©parÃ©es (CPU, mÃ©moire, I/Oâ€¦).
* **cgroup v2** : hiÃ©rarchie unifiÃ©e, introduite par systemd.

ğŸ“Œ VÃ©rification :

```bash
ls /sys/fs/cgroup/cgroup.controllers
```

* Si prÃ©sent â†’ v2.
* Sinon â†’ v1.

ğŸ“Œ Activation cgroup v2 (avec systemd) :

```bash
sudo grubby --update-kernel=ALL --args="systemd.unified_cgroup_hierarchy=1"
```

(sinon modifier `/etc/default/grub` puis `sudo update-grub`).

> âš ï¸ Changer de version nÃ©cessite un **redÃ©marrage complet**.

***

### ğŸ”¹ 4. Associer un conteneur Ã  ses cgroups

Chaque conteneur a un rÃ©pertoire de cgroup :

*   v1 (driver `cgroupfs`) :

    ```
    /sys/fs/cgroup/memory/docker/<longid>/
    ```
*   v1 (driver `systemd`) :

    ```
    /sys/fs/cgroup/memory/system.slice/docker-<longid>.scope/
    ```
*   v2 (driver `cgroupfs`) :

    ```
    /sys/fs/cgroup/docker/<longid>/
    ```
*   v2 (driver `systemd`) :

    ```
    /sys/fs/cgroup/system.slice/docker-<longid>.scope/
    ```

ğŸ‘‰ `<longid>` = lâ€™ID long du conteneur (`docker inspect`).

***

### ğŸ”¹ 5. Exemple : MÃ©triques mÃ©moire (`memory.stat`)

Dans un cgroup mÃ©moire, le fichier `memory.stat` donne des infos dÃ©taillÃ©es :

```txt
cache 11492564992
rss 1930993664
mapped_file 306728960
pgpgin 406632648
pgpgout 403355412
swap 0
pgfault 728281223
pgmajfault 1724
...
```

#### Les champs principaux :

* **cache** â†’ mÃ©moire utilisÃ©e comme cache disque (lecture/Ã©criture fichiers, tmpfs)
* **rss** â†’ mÃ©moire "pure" non liÃ©e au disque (heap, stack, mmap anonyme)
* **mapped\_file** â†’ mÃ©moire issue de fichiers mappÃ©s
* **pgfault** â†’ nombre de _page faults_ (accÃ¨s mÃ©moire nÃ©cessitant allocation)
* **pgmajfault** â†’ _page faults majeurs_ (nÃ©cessitant accÃ¨s disque)
* **swap** â†’ espace swap utilisÃ©
* **active\_anon / inactive\_anon** â†’ mÃ©moire anonyme active/inactive
* **active\_file / inactive\_file** â†’ cache fichiers actif/inactif
* **unevictable** â†’ mÃ©moire non expulsable (ex: clÃ©s cryptographiques via `mlock`)
* **hierarchical\_memory\_limit** â†’ limite mÃ©moire physique du cgroup
* **hierarchical\_memsw\_limit** â†’ limite RAM + swap

ğŸ“Œ Les versions avec prÃ©fixe `total_` incluent aussi les sous-cgroups.

***

### ğŸ”¹ 6. DiffÃ©rence "gauge" vs "counter"

* **Gauge** â†’ valeur instantanÃ©e (peut monter/descendre).
  * Ex : `rss`, `swap`
* **Counter** â†’ compteur dâ€™Ã©vÃ©nements (seulement croissant).
  * Ex : `pgfault`, `pgmajfault`

***

### ğŸš€ En rÃ©sumÃ©

* `docker stats` = vision rapide en temps rÃ©el (CPU, RAM, I/O).
* **cgroups** = mÃ©canisme Linux de suivi + limitation des ressources.
* **v1 vs v2** : diffÃ©rence dâ€™organisation, mais mÃªme finalitÃ©.
* Les fichiers comme `memory.stat` donnent un suivi **granulaire** (page faults, swap, cache).

## ğŸ“Š MÃ©triques CPU, I/O et RÃ©seau dans Docker

### ğŸ”¹ 1. CPU Metrics (`cpuacct.stat`)

Les mÃ©triques CPU dâ€™un conteneur se trouvent dans le contrÃ´leur **cpuacct** :

```
/sys/fs/cgroup/cpuacct/docker/<container_id>/cpuacct.stat
```

Contenu typique :

```txt
user 120
system 45
```

* **user** â†’ temps CPU passÃ© en mode utilisateur (exÃ©cution directe du code de lâ€™app).
* **system** â†’ temps CPU passÃ© en mode noyau (exÃ©cution des appels systÃ¨me pour le processus).

ğŸ“Œ MesurÃ© en **jiffies** (ticks de 1/100 s sur x86).\
ğŸ‘‰ 100 jiffies = 1 seconde.

Exemple :

* `user 120` = 1,2 s de CPU en mode user
* `system 45` = 0,45 s de CPU en mode noyau

***

### ğŸ”¹ 2. Block I/O Metrics (`blkio`)

Les mÃ©triques disque se trouvent dans le contrÃ´leur **blkio**.\
Fichiers principaux :

* **blkio.sectors**\
  â†’ nombre total de secteurs (512 octets) lus/Ã©crits par conteneur.
* **blkio.io\_service\_bytes**\
  â†’ nombre total de **bytes lus/Ã©crits**, diffÃ©renciÃ©s par :
  * lecture synchrone
  * Ã©criture synchrone
  * lecture asynchrone
  * Ã©criture asynchrone
* **blkio.io\_serviced**\
  â†’ nombre total dâ€™**opÃ©rations I/O** (peu importe la taille).
* **blkio.io\_queued**\
  â†’ nombre dâ€™opÃ©rations **en file dâ€™attente** pour ce cgroup.\
  (âš ï¸ une file vide â‰  conteneur inactif, car les I/O synchrones ne passent pas par la queue).

ğŸ‘‰ Ces infos permettent dâ€™identifier **quel conteneur stresse le disque**.

***

### ğŸ”¹ 3. Network Metrics

Contrairement au CPU et Ã  la mÃ©moire, les **cgroups ne fournissent pas directement de mÃ©triques rÃ©seau**.\
Raison : les interfaces rÃ©seau dÃ©pendent des **network namespaces**. Un conteneur peut avoir plusieurs interfaces (`eth0`, `lo`, â€¦), donc le suivi doit se faire au niveau **namespace**.

#### ğŸ“Œ Solutions possibles

1.  **iptables**\
    Ajouter une rÃ¨gle qui compte les paquets :

    ```bash
    iptables -I OUTPUT -p tcp --sport 80
    iptables -nxvL OUTPUT
    ```

    Cela donne nombre de paquets et dâ€™octets envoyÃ©s.
2.  **Counters dâ€™interfaces rÃ©seau**\
    Chaque conteneur a une interface `vethXXXX`.\
    VÃ©rifier les compteurs TX/RX avec :

    ```bash
    ip netns exec <container_ns> netstat -i
    ```

    Exemple de prÃ©paration :

    ```bash
    CID=<container_id>
    TASKS=/sys/fs/cgroup/devices/docker/$CID*/tasks
    PID=$(head -n 1 $TASKS)

    mkdir -p /var/run/netns
    ln -sf /proc/$PID/ns/net /var/run/netns/$CID

    ip netns exec $CID netstat -i
    ```

    Cela affiche les stats rÃ©seau depuis **lâ€™espace rÃ©seau du conteneur**.
3. **Collectd / Exporters**\
   Des outils comme **collectd** ou **cAdvisor** automatisent la collecte rÃ©seau pour Docker.

***

### ğŸ”¹ 4. Collecte haute performance

* DÃ©marrer un processus **persistant** (plutÃ´t que relancer une commande Ã  chaque fois).
* Utiliser lâ€™appel systÃ¨me **`setns()`** pour basculer un processus dans un namespace rÃ©seau et collecter les mÃ©triques.
* âš ï¸ Attention : ne pas garder le descripteur de namespace ouvert en permanence (risque de fuite rÃ©seau).

***

### ğŸ”¹ 5. Collecte Ã  la fin de vie du conteneur

Si on veut connaÃ®tre la **consommation totale** dâ€™un conteneur aprÃ¨s son arrÃªt :

1. Lancer un **processus de monitoring** et le placer dans le mÃªme cgroup (`tasks`).
2. Suivre les mÃ©triques rÃ©guliÃ¨rement.
3. Quand le conteneur sâ€™arrÃªte â†’ ce processus devient le dernier du cgroup.
4. Il collecte les derniÃ¨res mÃ©triques (CPU, mÃ©moire, I/O, rÃ©seau).
5. Il se replace dans le cgroup root et supprime le cgroup du conteneur (`rmdir`).

***

## ğŸš€ En rÃ©sumÃ©

* **CPU** : `cpuacct.stat` â†’ temps user/system en jiffies.
* **I/O Bloc** : `blkio.*` â†’ secteurs, octets, opÃ©rations, files dâ€™attente.
* **RÃ©seau** : pas via cgroups â†’ utiliser `iptables`, `netstat` via `ip netns`, ou collectd.
* On peut suivre en **temps rÃ©el** (`docker stats`, cAdvisor) ou en **fin de vie** du conteneur (via un processus dÃ©diÃ© dans son cgroup).
