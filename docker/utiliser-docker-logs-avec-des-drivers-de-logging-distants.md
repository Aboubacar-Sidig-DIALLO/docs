# ğŸ“‘ Utiliser docker logs avec des drivers de logging distants

### ğŸ”¹ Vue dâ€™ensemble

Normalement, lorsque tu configures un **driver de logging distant** (ex. : `fluentd`, `awslogs`, `gcplogs`, `splunk`, plugin externe, etc.), les logs ne sont **pas accessibles directement** avec `docker logs`.

ğŸ‘‰ Pour pallier Ã§a, Docker a introduit la fonctionnalitÃ© **dual logging** :

* Le **driver distant** continue dâ€™envoyer les logs vers sa destination externe.
* En parallÃ¨le, Docker utilise **le driver `local` comme cache** afin que tu puisses quand mÃªme utiliser `docker logs`.

***

### ğŸ”¹ Fonctionnement du cache local

* **Rotation activÃ©e par dÃ©faut** âœ…
* Limite : **5 fichiers de 20 MB** chacun (avant compression) par conteneur.
* Accessible via `docker logs <container_id>` mÃªme si ton conteneur envoie les logs vers AWS, GCP, Fluentd, etc.

***

### ğŸ”¹ Exemple : lecture avec et sans dual logging

#### Sans dual logging (exemple : `fluentd` configurÃ© **sans cache local**)

```bash
docker logs my_container
```

ğŸ‘‰ Renvoie une erreur ou rien du tout, car le driver `fluentd` ne supporte pas `docker logs`.

***

#### Avec dual logging activÃ© (par dÃ©faut si non support natif)

```bash
docker run -d \
  --log-driver=fluentd \
  --log-opt fluentd-address=localhost:24224 \
  alpine sh -c "while true; do echo hello $(date); sleep 2; done"
```

MÃªme si les logs partent vers `fluentd`, tu peux encore faire :

```bash
docker logs -f <container_id>
```

âœ… Tu vois les logs grÃ¢ce au **cache local**.

***

âš™ï¸ **Personnaliser la configuration du cache local**\
Dans `/etc/docker/daemon.json` :

```json
{
  "log-driver": "fluentd",
  "log-opts": {
    "fluentd-address": "localhost:24224"
  },
  "dual-logging": true,
  "log-opts-local": {
    "max-size": "10m",
    "max-file": "7"
  }
}
```

***

âš ï¸ **Attention**

* Dual logging **augmente lâ€™utilisation disque** (cache local + envoi distant).
* Tu peux **dÃ©sactiver dual logging** si tu veux uniquement du remote logging â†’ mais tu perdras la possibilitÃ© dâ€™utiliser `docker logs`.

## ğŸš« Utiliser `docker logs` **sans dual logging activÃ©**

Quand tu **dÃ©sactives le dual logging**, Docker **ne garde plus de copie locale** des logs. RÃ©sultat : `docker logs` ne fonctionne pas, et tu dois consulter les logs **directement dans ton backend distant** (Splunk, Fluentd, CloudWatch, etc.).

***

### ğŸ”¹ Exemple avec **Splunk**

#### Ã‰tape 1 : Configurer `daemon.json`

On dÃ©sactive explicitement le cache local avec `cache-disabled=true` :

```json
{
  "log-driver": "splunk",
  "log-opts": {
    "splunk-url": "https://splunk.example.com:8088",
    "splunk-token": "your-splunk-token",
    "splunk-insecureskipverify": "true",
    "cache-disabled": "true"
  }
}
```

Puis on redÃ©marre le dÃ©mon :

```bash
sudo systemctl restart docker
```

***

#### Ã‰tape 2 : Lancer un conteneur

```bash
docker run -d --name testlog busybox top
```

***

#### Ã‰tape 3 : Tenter de lire les logs

```bash
docker logs testlog
```

ğŸ‘‰ RÃ©sultat :

```
Error response from daemon: configured logging driver does not support reading
```

***

### ğŸ”¹ RÃ©sumÃ©

* âœ… Les logs partent bien vers **Splunk**.
* ğŸš« Impossible de les lire avec `docker logs`.
* Tu dois **consulter les logs depuis ton backend** (Splunk dans ce cas).

## âœ… Utiliser `docker logs` **avec dual logging activÃ©**

Quand tu **gardes le dual logging activÃ©** (câ€™est le mode par dÃ©faut), Docker conserve une **copie locale** des logs, mÃªme si tu utilises un **driver de logging distant** comme Splunk, Fluentd ou CloudWatch.

ğŸ‘‰ RÃ©sultat : tu peux **continuer Ã  utiliser `docker logs`** en plus de ton systÃ¨me de logs externe.

***

### ğŸ”¹ Exemple avec Splunk

#### Ã‰tape 1 : Configurer `daemon.json`

Ici on dÃ©finit le driver par dÃ©faut sur **Splunk**, mais **sans dÃ©sactiver** le cache (`cache-disabled` nâ€™apparaÃ®t pas) :

```json
{
  "log-driver": "splunk",
  "log-opts": {
    "splunk-url": "https://splunk.example.com:8088",
    "splunk-token": "your-splunk-token",
    "splunk-insecureskipverify": "true"
  }
}
```

Puis on redÃ©marre le dÃ©mon Docker :

```bash
sudo systemctl restart docker
```

***

#### Ã‰tape 2 : Lancer un conteneur

```bash
docker run -d --name testlog busybox top
```

***

#### Ã‰tape 3 : Lire les logs avec `docker logs`

MÃªme si Splunk reÃ§oit dÃ©jÃ  les logs, tu peux **aussi** les lire en local :

```bash
docker logs testlog
```

ğŸ‘‰ Exemple de sortie :

```
2019-02-04T19:48:15.423Z [INFO]  core: marked as sealed
2019-02-04T19:48:15.423Z [INFO]  core: pre-seal teardown starting
2019-02-04T19:48:15.423Z [INFO]  core: stopping cluster listeners
2019-02-04T19:48:15.423Z [INFO]  core: shutting down forwarding rpc listeners
2019-02-04T19:48:15.599Z [INFO]  core: rpc listeners successfully shut down
2019-02-04T19:48:15.599Z [INFO]  core: cluster listeners successfully shut down
```

***

### ğŸ”¹ RÃ©sumÃ©

* ğŸš€ **Avec dual logging** : logs accessibles Ã  la fois dans `docker logs` **et** dans Splunk.
* âŒ **Sans dual logging** : logs envoyÃ©s uniquement dans Splunk (erreur si tu fais `docker logs`).
* â„¹ï¸ Pour les drivers qui supportent dÃ©jÃ  la lecture (`json-file`, `local`, `journald`), il nâ€™y a pas de diffÃ©rence.

0, or false).

**ChatGPT a dit :**

Parfait ğŸ‘ ! Voici un rÃ©cap clair et dÃ©taillÃ© des **options de configuration du dual logging cache** (qui est en fait basÃ© sur le driver `local` mais avec le prÃ©fixe `cache-`) :

***

## âš™ï¸ Options de configuration du dual logging cache

| Option             | Valeur par dÃ©faut | Description                                                                                                                                                                                                                                                                                         |
| ------------------ | ----------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **cache-disabled** | `"false"`         | <p>DÃ©sactive complÃ¨tement le cache local. Valeur boolÃ©enne sous forme de chaÃ®ne (<code>"true"</code>, <code>"false"</code>, <code>"1"</code>, <code>"0"</code>).<br>ğŸ‘‰ Si activÃ© (<code>true</code>), tu ne pourras <strong>plus utiliser <code>docker logs</code></strong> pour lire les logs.</p> |
| **cache-max-size** | `"20m"`           | <p>Taille maximale dâ€™un fichier de log avant rotation. Format : entier + unitÃ© (<code>k</code>, <code>m</code>, <code>g</code>).<br>ğŸ‘‰ Exemple : <code>"50m"</code> = rotation aprÃ¨s 50 Mo.</p>                                                                                                     |
| **cache-max-file** | `"5"`             | Nombre maximum de fichiers de logs conservÃ©s. Si la rotation crÃ©e plus de fichiers, les plus anciens sont supprimÃ©s.                                                                                                                                                                                |
| **cache-compress** | `"true"`          | <p>Active ou dÃ©sactive la <strong>compression</strong> des fichiers de logs aprÃ¨s rotation. Valeur boolÃ©enne sous forme de chaÃ®ne.<br>ğŸ‘‰ Compression = gain dâ€™espace disque mais un peu plus de CPU.</p>                                                                                            |

***

## ğŸ”¹ Exemple : Configurer globalement dans `daemon.json`

ğŸ‘‰ Ici on configure le cache pour garder **10 fichiers de 50 Mo max chacun, sans compression** :

```json
{
  "log-driver": "splunk",
  "log-opts": {
    "splunk-url": "https://splunk.example.com:8088",
    "splunk-token": "your-splunk-token",
    "splunk-insecureskipverify": "true",
    "cache-max-size": "50m",
    "cache-max-file": "10",
    "cache-compress": "false"
  }
}
```

Puis on redÃ©marre Docker :

```bash
sudo systemctl restart docker
```

***

## ğŸ”¹ Exemple : Configurer au niveau dâ€™un conteneur

```bash
docker run -d \
  --log-driver=splunk \
  --log-opt splunk-url=https://splunk.example.com:8088 \
  --log-opt splunk-token=your-splunk-token \
  --log-opt cache-max-size=100m \
  --log-opt cache-max-file=3 \
  --log-opt cache-compress=true \
  busybox top
```

***

âœ… RÃ©sultat :

* Logs envoyÃ©s **Ã  Splunk**
* Copie locale avec rotation : max **3 fichiers de 100 Mo** compressÃ©s
* Accessible avec `docker logs <container>`

## ğŸš« DÃ©sactiver le cache de double journalisation (dual logging cache)

Le **dual logging cache** permet de lire les logs avec `docker logs` mÃªme si tu utilises un driver de logs **qui ne supporte pas la lecture locale** (comme `splunk`, `fluentd`, `awslogs`, etc.).

ğŸ‘‰ **Quand le dÃ©sactiver ?**

* Si tu veux **Ã©conomiser de lâ€™espace disque** sur la machine hÃ´te.
* Si tu nâ€™as **aucun besoin** dâ€™utiliser `docker logs` (tu lis uniquement via ton systÃ¨me de logs distant).
* Si tu veux Ã©viter une **double Ã©criture** (locale + remote).

***

### ğŸ”¹ DÃ©sactiver globalement (via `daemon.json`)

Exemple : activer `splunk` comme driver de logs **par dÃ©faut** et dÃ©sactiver le cache :

```json
{
  "log-driver": "splunk",
  "log-opts": {
    "cache-disabled": "true",
    "splunk-url": "https://splunk.example.com:8088",
    "splunk-token": "your-splunk-token",
    "splunk-insecureskipverify": "true"
  }
}
```

Puis redÃ©marre Docker :

```bash
sudo systemctl restart docker
```

***

### ğŸ”¹ DÃ©sactiver pour un seul conteneur

```bash
docker run -d \
  --log-driver=splunk \
  --log-opt splunk-url=https://splunk.example.com:8088 \
  --log-opt splunk-token=your-splunk-token \
  --log-opt cache-disabled=true \
  busybox top
```

***

### âš ï¸ Notes importantes

*   Avec `cache-disabled=true`, la commande **`docker logs` ne fonctionnera plus** pour ce conteneur.\
    Exemple :

    ```bash
    docker logs <container>
    Error response from daemon: configured logging driver does not support reading
    ```
* Cela nâ€™a **aucun effet** si tu utilises un driver qui supporte dÃ©jÃ  la lecture locale (`json-file`, `local`, `journald`).

