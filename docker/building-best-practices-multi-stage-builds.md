# ğŸ› ï¸ Building best practices â€“ Multi-stage builds

### ğŸ¯ Pourquoi utiliser les multi-stage builds ?

* **RÃ©duction de taille** :\
  Les dÃ©pendances, outils de compilation ou fichiers temporaires ne polluent pas lâ€™image finale.
* **SÃ©paration claire** :\
  On distingue la phase de **construction** (build, compilation, tests) de la phase **exÃ©cution** (runtime minimal).
* **Performances** :\
  Certaines Ã©tapes peuvent Ãªtre parallÃ©lisÃ©es et rÃ©utilisÃ©es grÃ¢ce au cache Docker.
* **SÃ©curitÃ©** :\
  On ne garde que le strict nÃ©cessaire â†’ moins de surface dâ€™attaque.

***

### ğŸ” Exemple sans multi-stage (classique mais lourd)

```dockerfile
FROM golang:1.22

WORKDIR /app
COPY . .
RUN go build -o myapp .

CMD ["./myapp"]
```

ğŸ‘‰ ProblÃ¨me :

* Lâ€™image finale contient **Go + outils de build + code source complet**, inutile en production.

***

### âœ… Exemple avec multi-stage build

```dockerfile
# Ã‰tape 1 : Build
FROM golang:1.22 AS builder
WORKDIR /app
COPY . .
RUN go build -o myapp .

# Ã‰tape 2 : Runtime minimal
FROM debian:bookworm-slim
WORKDIR /app
COPY --from=builder /app/myapp .
CMD ["./myapp"]
```

ğŸ‘‰ Avantages :

* Lâ€™image finale ne contient que :
  * le binaire `myapp`
  * le runtime Debian minimal
* La taille passe de **plusieurs centaines de Mo** â†’ **quelques Mo seulement**.

***

### âš¡ Exemple avancÃ© avec plusieurs Ã©tapes

On peut chaÃ®ner plusieurs Ã©tapes :

1. Compilation â†’
2. Tests â†’
3. Image finale allÃ©gÃ©e.

```dockerfile
# Ã‰tape 1 : Build
FROM node:20 AS build
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build

# Ã‰tape 2 : Tests
FROM build AS test
RUN npm run test

# Ã‰tape 3 : Production
FROM nginx:alpine
COPY --from=build /app/dist /usr/share/nginx/html
```

ğŸ‘‰ Ici :

* Ã‰tape `build` â†’ compile lâ€™application.
* Ã‰tape `test` â†’ vÃ©rifie la qualitÃ© (mais nâ€™est pas incluse dans lâ€™image finale).
* Ã‰tape `production` â†’ ne garde que le contenu `dist/` servi par **Nginx**.

***

## ğŸ‰ Conclusion

Les **multi-stage builds** sont une **meilleure pratique incontournable** pour :

* optimiser la taille des images,
* rÃ©duire les dÃ©pendances inutiles,
* sÃ©curiser vos dÃ©ploiements.

## ğŸ› ï¸ Building best practices â€“ **CrÃ©er des stages rÃ©utilisables**

### ğŸ¯ Pourquoi ?

* **Optimisation** :\
  Les parties communes (dÃ©pendances, outils, configurations) sont construites **une seule fois** et mises en cache.
* **DRY (Donâ€™t Repeat Yourself)** :\
  Au lieu de recopier les mÃªmes instructions dans plusieurs Dockerfiles/stages, tu centralises.
* **EfficacitÃ© mÃ©moire** :\
  Les images dÃ©rivÃ©es partagent les couches dÃ©jÃ  construites.
* **Maintenance** :\
  Une modification du stage commun se propage automatiquement Ã  toutes les variantes.

***

### ğŸ” Exemple simple : applications Node.js

Supposons que tu construises plusieurs variantes (API, worker, frontend) qui partagent :

* la mÃªme base Node.js,
* les mÃªmes dÃ©pendances `package.json`.

ğŸ‘‰ **Stage rÃ©utilisable :**

```dockerfile
# syntax=docker/dockerfile:1

# Ã‰tape commune = dÃ©pendances Node.js
FROM node:20 AS base
WORKDIR /app
COPY package*.json ./
RUN npm install
```

ğŸ‘‰ **API image :**

```dockerfile
FROM base AS api
COPY api/ .
CMD ["node", "server.js"]
```

ğŸ‘‰ **Worker image :**

```dockerfile
FROM base AS worker
COPY worker/ .
CMD ["node", "worker.js"]
```

ğŸ‘‰ **Frontend image :**

```dockerfile
FROM base AS frontend
COPY frontend/ .
RUN npm run build
CMD ["npm", "start"]
```

***

### âœ… Avantages

* `npm install` nâ€™est exÃ©cutÃ© quâ€™une seule fois (cachÃ© dans `base`).
* Les 3 images (`api`, `worker`, `frontend`) partagent la mÃªme base â†’ **gains de temps + mÃ©moire**.
* Si tu mets Ã  jour une dÃ©pendance dans `package.json`, toutes les images hÃ©ritent du changement.

***

### âš¡ Exemple avancÃ© : pipeline CI/CD

Tu peux mÃªme chaÃ®ner les stages pour centraliser **build + tests + prod** :

```dockerfile
FROM node:20 AS deps
WORKDIR /app
COPY package*.json ./
RUN npm ci

FROM deps AS build
COPY . .
RUN npm run build

FROM deps AS test
COPY . .
RUN npm test

FROM nginx:alpine AS prod
COPY --from=build /app/dist /usr/share/nginx/html
```

ğŸ‘‰ Ici, `deps` sert de **stage commun rÃ©utilisable** pour `build`, `test` et potentiellement dâ€™autres.

***

## ğŸ‰ Conclusion

* Les **stages rÃ©utilisables** permettent de **factoriser**, **gagner en vitesse** et **Ã©viter la duplication**.
* Câ€™est particuliÃ¨rement puissant si tu as **plusieurs images similaires** dans un mÃªme projet (monorepos, microservices).

## ğŸ›¡ï¸ Bonnes pratiques de construction â€“ **Choisir la bonne image de base**

***

### ğŸ¯ Pourquoi câ€™est important ?

La **premiÃ¨re Ã©tape** pour obtenir une image **sÃ©curisÃ©e et fiable** est de **choisir correctement lâ€™image de base** (`FROM â€¦` dans ton Dockerfile).\
ğŸ‘‰ Le choix du point de dÃ©part impacte :

* la **sÃ©curitÃ©** (moins de failles connues),
* la **taille de lâ€™image** (rapiditÃ© de tÃ©lÃ©chargement et dÃ©ploiement),
* la **portabilitÃ©** (exÃ©cution fluide sur diffÃ©rentes plateformes).

***

### âœ… Sources fiables pour les images de base

Docker met en avant plusieurs types dâ€™images **validÃ©es et vÃ©rifiÃ©es** ğŸ”’ :

#### 1. **Docker Official Images**

ğŸ“¦ Collection **officielle et certifiÃ©e** par Docker.

* Documentation claire,
* Suivi des bonnes pratiques,
* Mises Ã  jour rÃ©guliÃ¨res.\
  ğŸ‘‰ Un excellent **point de dÃ©part** pour la majoritÃ© des projets.

#### 2. **Verified Publisher Images**

ğŸ¢ Images publiÃ©es par des **Ã©diteurs partenaires** de Docker (Microsoft, Red Hat, etc.).

* Docker vÃ©rifie lâ€™authenticitÃ© du contenu,
* Gage de **qualitÃ© et fiabilitÃ©**.

#### 3. **Docker-Sponsored Open Source**

ğŸŒ Images publiÃ©es par des projets **open source sponsorisÃ©s par Docker**.

* Maintenus par les communautÃ©s,
* BÃ©nÃ©ficient du programme officiel.

ğŸ‘‰ Lorsque tu explores Docker Hub, repÃ¨re les **badges** ğŸ… (Official / Verified Publisher) pour savoir si lâ€™image est **sÃ©curisÃ©e et reconnue**.

<figure><img src="../.gitbook/assets/image.png" alt=""><figcaption></figcaption></figure>

***

### âš¡ Bonnes pratiques de choix dâ€™image de base

* **Minimalisme = sÃ©curitÃ© + performance** ğŸš€\
  Plus lâ€™image est **petite**, plus elle est rapide Ã  tÃ©lÃ©charger, portable, et moins elle embarque de dÃ©pendances vulnÃ©rables.
* **SÃ©parer build et production** ğŸ—ï¸â¡ï¸ğŸ­\
  Utilise **deux types dâ€™images** :
  * Une **image riche** (avec compilateurs, outils de debug, etc.) pour le **build et les tests unitaires**.
  * Une **image slim** (trÃ¨s lÃ©gÃ¨re, sans outils inutiles) pour la **production**.\
    ğŸ‘‰ Cela **rÃ©duit la surface dâ€™attaque** et accÃ©lÃ¨re le dÃ©ploiement.

Exemple :

```dockerfile
# Ã‰tape de build (image riche)
FROM golang:1.22 AS build
WORKDIR /app
COPY . .
RUN go build -o myapp

# Ã‰tape de production (image minimaliste)
FROM alpine:3.19
COPY --from=build /app/myapp /usr/local/bin/myapp
ENTRYPOINT ["myapp"]
```

***

### ğŸ‰ RÃ©sumÃ©

* Toujours choisir une **image officielle, vÃ©rifiÃ©e ou sponsorisÃ©e** ğŸ“¦.
* **Moins câ€™est gros, mieux câ€™est** â†’ opte pour des images minimalistes ğŸª¶.
* SÃ©pare **environnement de build** et **environnement de prod** pour sÃ©curitÃ© et performance.

## ğŸ”„ Bonnes pratiques de construction â€“ **Reconstruisez vos images rÃ©guliÃ¨rement**

***

### ğŸ“¦ Pourquoi reconstruire ses images souvent ?

Les **images Docker sont immuables** : une fois construites, elles figent lâ€™Ã©tat exact de :

* ton **image de base** (ex. `ubuntu:24.04`),
* tes **librairies installÃ©es**,
* tes **dÃ©pendances**.

ğŸ‘‰ Cela veut dire que si tu ne reconstruis pas ton image rÃ©guliÃ¨rement, tu risques de :

* rester avec des **versions obsolÃ¨tes** de bibliothÃ¨ques,
* manquer des **mises Ã  jour de sÃ©curitÃ© critiques**,
* embarquer des **failles connues** dans tes dÃ©ploiements.

***

### ğŸ› ï¸ Comment garder ses images Ã  jour ?

#### 1. **Reconstruire rÃ©guliÃ¨rement**

Planifie des reconstructions frÃ©quentes (CI/CD, jobs planifiÃ©s) pour tâ€™assurer que :

* tes images incluent les **derniers correctifs**,
* les **dÃ©pendances critiques** sont Ã  jour.

***

#### 2. **Forcer un build sans cache**

Par dÃ©faut, Docker optimise en rÃ©utilisant le cache des couches prÃ©cÃ©dentes.\
Mais pour sâ€™assurer dâ€™un **rafraÃ®chissement complet** des dÃ©pendances, utilise `--no-cache` :

```bash
docker build --no-cache -t my-image:my-tag .
```

ğŸ‘‰ Cela Ã©vite dâ€™utiliser des versions en cache et garantit un **tÃ©lÃ©chargement frais** des images de base et dÃ©pendances.

***

#### 3. **Exemple avec Ubuntu**

Voici un Dockerfile qui utilise lâ€™image Ubuntu `24.04`.

âš ï¸ Attention : ce tag Ã©volue avec le temps. Lâ€™Ã©diteur (Canonical) peut republier la mÃªme balise avec un **nouveau snapshot corrigÃ©**.

```dockerfile
# syntax=docker/dockerfile:1
FROM ubuntu:24.04
RUN apt-get -y update && apt-get install -y --no-install-recommends python3
```

En reconstruisant ton image **avec `--no-cache`**, tu forces :

* le tÃ©lÃ©chargement de la **derniÃ¨re version dâ€™Ubuntu 24.04**,
* lâ€™installation des **derniers paquets apt sÃ©curisÃ©s**.

***

#### 4. **Pense au â€œpinningâ€ (fixer les versions)**

âš“ Pour Ã©viter les surprises (changements majeurs involontaires), tu peux :

* **Ã©pingle une version prÃ©cise** (`ubuntu:24.04.1` plutÃ´t que `ubuntu:24.04`).
* garantir que ton build sera **reproductible** et **stable**, tout en prÃ©voyant des rebuilds planifiÃ©s pour intÃ©grer les patchs.

***

### ğŸ“¸ Illustration mentale

Imagine ton image comme une **photo instantanÃ©e** ğŸ“· :

* reconstruire sans cache = reprendre une **nouvelle photo Ã  la lumiÃ¨re du jour** ğŸŒ,
* laisser traÃ®ner ton image = garder une **vieille photo jaunie** ğŸ“œ qui ne reflÃ¨te plus la rÃ©alitÃ©.

***

âœ… **RÃ©sumÃ© :**

* Reconstruis rÃ©guliÃ¨rement pour **sÃ©curitÃ© + fraÃ®cheur**.
* Utilise `--no-cache` pour forcer un build propre.
* Ã‰pingle tes versions pour garder des builds **prÃ©visibles et stables**.

## ğŸš« Bonnes pratiques de construction â€“ **Exclure avec `.dockerignore`**

***

### ğŸ“¦ Pourquoi utiliser `.dockerignore` ?

Lorsque tu construis une image avec `docker build`, **tout le contexte de build** (les fichiers de ton projet) est envoyÃ© au dÃ©mon Docker.

ğŸ‘‰ ProblÃ¨me : si tu nâ€™exclus pas les fichiers inutiles, tu risques :

* dâ€™augmenter la **taille du contexte de build**,
* de **ralentir les builds** (transfert inutile de fichiers),
* dâ€™embarquer accidentellement des **fichiers sensibles** (mots de passe, clÃ©s SSH, etc.),
* de compliquer la maintenance et la sÃ©curitÃ©.

La solution âœ… â†’ **`.dockerignore`**, qui fonctionne comme un `.gitignore` : tu indiques quels fichiers/dossiers **ignorer** lors du build.

***

### ğŸ› ï¸ Exemple simple

Tu veux ignorer tous les fichiers Markdown (`.md`) non pertinents pour ton build :

`.dockerignore`

```dockerignore
*.md
```

ğŸ‘‰ RÃ©sultat : tous les fichiers `README.md`, `docs/*.md`, etc. **ne seront pas envoyÃ©s dans le contexte de build**.

***

### ğŸ“– Cas dâ€™usage courant

Voici quelques exemples pratiques Ã  mettre dans `.dockerignore` :

```dockerignore
# Ignorer fichiers temporaires
*.log
*.tmp

# Ignorer rÃ©pertoires de dÃ©pendances
node_modules
target
dist

# Ignorer fichiers de contrÃ´le de version
.git
.gitignore

# Ignorer fichiers de configuration locaux
.env
docker-compose.override.yml
```

***

### ğŸ“¸ Illustration (vue conceptuelle)

* Sans `.dockerignore` : ğŸ“¦ ton **contexte de build gonfle** avec des fichiers inutiles.
* Avec `.dockerignore` : âœ‚ï¸ tu ne transfÃ¨res que **ce qui est nÃ©cessaire** â†’ build plus rapide, plus propre, plus sÃ©curisÃ©.

***

### âœ… RÃ©sumÃ©

* `.dockerignore` = ton **filet de sÃ©curitÃ©** contre les fichiers inutiles et sensibles ğŸš«.
* RÃ©duit la **taille**, accÃ©lÃ¨re les **builds**, amÃ©liore la **sÃ©curitÃ©**.
* Fonctionne **exactement comme un `.gitignore`** â†’ exclusion par motifs (patterns glob).

## âš¡ Bonnes pratiques de construction â€“ **CrÃ©er des conteneurs Ã©phÃ©mÃ¨res**

***

### ğŸ§© Quâ€™est-ce quâ€™un conteneur Ã©phÃ©mÃ¨re ?

Un conteneur **Ã©phÃ©mÃ¨re** est un conteneur qui peut Ãªtre :

* **arrÃªtÃ©** ğŸ›‘,
* **dÃ©truit** ğŸ—‘ï¸,
* **reconstruit** ğŸ—ï¸,
* **remplacÃ©** ğŸ”„

ğŸ‘‰ Le tout avec **un minimum absolu de configuration manuelle**.

En dâ€™autres termes : **rien dans ton conteneur ne doit Ãªtre unique ou irremplaÃ§able**.

***

### ğŸ¯ Pourquoi viser lâ€™Ã©phÃ©mÃ¨re ?

Cela rejoint les principes de **The Twelve-Factor App** (mÃ©thodologie de conception dâ€™applications modernes et cloud-native).

#### Les avantages :

* ğŸ”„ **ScalabilitÃ©** : tu peux crÃ©er/dÃ©truire des conteneurs Ã  la volÃ©e (auto-scaling, load balancing).
* ğŸ› ï¸ **Maintenance simplifiÃ©e** : si un conteneur est corrompu, tu le remplaces, pas besoin de le rÃ©parer.
* ğŸš€ **DÃ©ploiements rapides** : un conteneur stateless dÃ©marre sans dÃ©pendre de configurations locales compliquÃ©es.
* ğŸ”’ **SÃ©curitÃ© accrue** : pas de donnÃ©es sensibles stockÃ©es dans le conteneur â†’ moins de risques de fuite.

***

### ğŸ“¦ Comment crÃ©er des conteneurs Ã©phÃ©mÃ¨res ?

#### 1. **Aucun Ã©tat persistant Ã  lâ€™intÃ©rieur du conteneur**

* Ne stocke pas de fichiers de logs, uploads ou bases de donnÃ©es dans le conteneur.
* Utilise des volumes ou des services externes pour la persistance (base de donnÃ©es, stockage objet type S3, etc.).

***

#### 2. **Configuration via variables dâ€™environnement**

Au lieu de mettre ta config en dur dans le conteneur :\
ğŸ‘‰ Passe-la via des **variables dâ€™environnement** (`-e` ou `.env`).

Exemple :

```bash
docker run -e DATABASE_URL=mysql://user:pass@db/app my-app
```

***

#### 3. **Facile Ã  remplacer**

Ton conteneur doit Ãªtre **stateless** :

* Tu arrÃªtes â†’ ğŸš« pas de perte critique.
* Tu relances â†’ âœ… il reprend son rÃ´le automatiquement.

***

### ğŸ“¸ Illustration conceptuelle

Imagine ton conteneur comme une **canette jetable ğŸ¥¤** :

* Tu lâ€™utilises â†’ tu le jettes â†’ tu en prends une nouvelle.\
  Contrairement Ã  une **bouteille rechargeable en verre ğŸ¾** oÃ¹ tu dois nettoyer, garder et entretenir.

Docker encourage le modÃ¨le **canette jetable** â†’ pratique, rapide, sans Ã©tat persistant.

***

### âœ… RÃ©sumÃ©

* Un conteneur doit Ãªtre **Ã©phÃ©mÃ¨re, stateless, jetable**.
* Stockage et configuration doivent venir **de lâ€™extÃ©rieur** (volumes, env vars, services).
* Cette approche facilite la **scalabilitÃ©, la rÃ©silience et la sÃ©curitÃ©**.

## ğŸ§¹ Bonnes pratiques de construction â€“ **Nâ€™installez pas de paquets inutiles**

***

### ğŸ¯ Le principe

Lors de la crÃ©ation dâ€™images, on est parfois tentÃ© dâ€™installer des outils "au cas oÃ¹" (par exemple un Ã©diteur de texte comme `vim` dans une image de base de donnÃ©es).\
ğŸ‘‰ Mauvaise idÃ©e !

Chaque paquet supplÃ©mentaire =

* ğŸ“¦ **plus de dÃ©pendances**,
* ğŸ•°ï¸ **plus de temps de build**,
* ğŸ˜ **une image plus lourde**,
* ğŸ”“ **une surface dâ€™attaque plus grande** (plus de failles potentielles).

***

### ğŸš« Exemple de mauvaise pratique

Un Dockerfile qui installe des outils non nÃ©cessaires :

```dockerfile
FROM postgres:16
RUN apt-get update && apt-get install -y vim curl
```

ğŸ‘‰ Ici, `vim` nâ€™apporte rien pour une image PostgreSQL, mais alourdit et complexifie inutilement lâ€™image.

***

### âœ… Bonne pratique

Nâ€™installe que ce qui est **strictement nÃ©cessaire** Ã  ton application.\
Si tu as besoin ponctuellement dâ€™outils pour du **debug**, utilise un conteneur sÃ©parÃ© (par exemple basÃ© sur `alpine` ou `ubuntu`) pour diagnostiquer ton systÃ¨me.

Exemple minimaliste :

```dockerfile
FROM python:3.12-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
CMD ["python", "main.py"]
```

ğŸ‘‰ Ici, on ne garde **que Python et les dÃ©pendances utiles** Ã  lâ€™application.

***

### ğŸ“¸ Illustration conceptuelle

Imagine ton image comme un **sac Ã  dos de randonnÃ©e ğŸ’** :

* Si tu le charges dâ€™objets inutiles (textes, gadgets, outils que tu nâ€™utiliseras jamais), il devient **lourd et encombrant**.
* Si tu ne prends que lâ€™essentiel, ton sac reste **lÃ©ger, rapide et efficace**.

***

### âœ… RÃ©sumÃ©

* **Moins de paquets = mieux** ğŸ¯.
* Nâ€™installe que ce dont ton application a **rÃ©ellement besoin**.
* Pas de "juste au cas oÃ¹" â†’ chaque outil doit avoir une vraie raison dâ€™Ãªtre dans ton image.

## ğŸ§© Bonnes pratiques de construction â€“ **Dissocier les applications (Decouple applications)**

***

### ğŸ¯ Le principe

ğŸ‘‰ **Chaque conteneur doit avoir un seul rÃ´le clair**.\
Lâ€™idÃ©e est de dÃ©couper une application en **plusieurs services autonomes**, chacun tournant dans son propre conteneur.

Exemple classique dâ€™une stack web :

* ğŸŒ **Web serveur** (ex. Nginx ou Apache),
* ğŸ—„ï¸ **Base de donnÃ©es** (ex. PostgreSQL, MySQL),
* âš¡ **Cache en mÃ©moire** (ex. Redis, Memcached).

Chaque service â†’ **1 conteneur indÃ©pendant**, reliÃ© aux autres via un **rÃ©seau Docker**.

***

### ğŸš€ Pourquoi dÃ©coupler ?

* **ScalabilitÃ© horizontale** : tu peux scaler indÃ©pendamment (par ex. 5 instances web + 1 DB + 2 Redis).
* **RÃ©utilisabilitÃ©** : le mÃªme conteneur Redis peut Ãªtre utilisÃ© dans plusieurs projets.
* **Maintenance simplifiÃ©e** : si un service tombe, tu remplaces _uniquement_ le conteneur fautif.
* **ModularitÃ© & clartÃ©** : chaque conteneur fait UNE chose â†’ plus facile Ã  comprendre et Ã  dÃ©boguer.

***

### âš–ï¸ La rÃ¨gle du â€œ1 conteneur = 1 processâ€

Une bonne **rÃ¨gle de base** est de limiter chaque conteneur Ã  **un seul processus principal**.

Mais attention âš ï¸ â†’ ce nâ€™est **pas une rÃ¨gle absolue** :

* Certains programmes gÃ¨rent eux-mÃªmes plusieurs processus (ex. **Celery** avec plusieurs workers, **Apache** qui spawn un process par requÃªte).
* Tu peux aussi dÃ©marrer un conteneur avec un **init process** pour gÃ©rer proprement les sous-processus.

ğŸ‘‰ Utilise ton **jugement** pour garder tes conteneurs **modulaires et propres**, sans tomber dans lâ€™extrÃªme.

***

### ğŸ”— Communication entre conteneurs

Si tes conteneurs dÃ©pendent les uns des autres :

* Utilise les **rÃ©seaux Docker** (`docker network create mynet`) pour les connecter.
* Exemple : ton application web peut communiquer avec la base via `db:5432` au lieu de `localhost`.

***

### ğŸ“¸ Illustration conceptuelle

Imagine ton application comme un **ensemble de Lego ğŸ§±** :

* Chaque piÃ¨ce = un conteneur avec un rÃ´le prÃ©cis.
* Tu peux les **assembler**, **remplacer**, ou **multiplier** sans casser toute la construction.

***

### âœ… RÃ©sumÃ©

* **Un conteneur = une responsabilitÃ© claire**.
* Favorise la **modularitÃ©** et la **scalabilitÃ© horizontale**.
* La rÃ¨gle du â€œ1 process par conteneurâ€ est une bonne base, mais garde de la souplesse.
* Connecte tes conteneurs via des **rÃ©seaux Docker**.

## ğŸ“‘ Bonnes pratiques de construction â€“ **Trier les arguments multi-lignes**

***

### ğŸ¯ Le principe

Quand tu as une commande avec **plusieurs Ã©lÃ©ments listÃ©s sur plusieurs lignes** (souvent lors dâ€™un `apt-get install` ou `pip install`), trie-les **par ordre alphabÃ©tique**.

ğŸ‘‰ Pourquoi ?

* âœ… Plus facile Ã  **maintenir** : tu retrouves rapidement un paquet.
* âœ… Tu Ã©vites les **doublons accidentels**.
* âœ… Les **revues de code (PRs)** sont plus claires â†’ on voit immÃ©diatement ce qui a changÃ©.
* âœ… Plus simple Ã  mettre Ã  jour (ajout/suppression rapide).

ğŸ’¡ Astuce : ajoute toujours un **espace avant le `\`** pour rendre la continuitÃ© encore plus lisible.

***

### ğŸš« Exemple non triÃ© (confus)

```dockerfile
RUN apt-get update && apt-get install -y --no-install-recommends \
  git \
  subversion \
  bzr \
  mercurial \
  cvs \
  && rm -rf /var/lib/apt/lists/*
```

Ici, impossible de voir en un coup dâ€™Å“il si `git` est dÃ©jÃ  listÃ©, ou si lâ€™ordre a du sens.

***

### âœ… Exemple triÃ© (clair et propre)

```dockerfile
RUN apt-get update && apt-get install -y --no-install-recommends \
  bzr \
  cvs \
  git \
  mercurial \
  subversion \
  && rm -rf /var/lib/apt/lists/*
```

ğŸ‘‰ Lecture fluide, aucun doublon, maintenance facilitÃ©e.

***

### ğŸ“¸ Illustration conceptuelle

Imagine que tu ranges ta bibliothÃ¨que ğŸ“š :

* Sans tri â†’ tu cherches ton livre partout, câ€™est le chaos.
* Avec tri alphabÃ©tique â†’ tu trouves tout en quelques secondes.

MÃªme logique pour les listes multi-lignes dans un Dockerfile.

***

### âœ… RÃ©sumÃ©

* Toujours **trier alphabÃ©tiquement** les listes dâ€™installations ou de dÃ©pendances.
* Ajoute un **espace avant le `\`** pour la lisibilitÃ©.
* Gain Ã©norme en **clartÃ©, maintenance et qualitÃ© des PRs**.

## âš¡ Bonnes pratiques de construction â€“ **Tirer parti du cache de build**

***

### ğŸ“¦ Le principe

Lorsque Docker construit une image Ã  partir dâ€™un **Dockerfile**, il suit les instructions **ligne par ligne** (de haut en bas).\
ğŸ‘‰ Ã€ chaque Ã©tape, Docker regarde :

* si le rÃ©sultat de lâ€™instruction existe dÃ©jÃ  dans le **cache de build**,
* et sâ€™il peut **rÃ©utiliser** cette version au lieu de tout reconstruire.

Câ€™est ce mÃ©canisme qui fait que parfois ton build est **ultra-rapide** (car il rÃ©utilise le cache), et parfois **plus lent** (car une Ã©tape a invalidÃ© le cache).

***

### ğŸ”„ Comprendre lâ€™invalidation du cache

âš ï¸ Si une instruction change, toutes les **instructions suivantes** sont Ã©galement **reconstruites**.\
Exemple :

```dockerfile
# Ã‰tape 1
FROM python:3.12

# Ã‰tape 2
COPY requirements.txt .

# Ã‰tape 3
RUN pip install -r requirements.txt

# Ã‰tape 4
COPY . .
```

* Si tu modifies **`requirements.txt`**, lâ€™Ã©tape 2 change â†’ le cache de lâ€™Ã©tape 3 est invalidÃ© â†’ `pip install` doit Ãªtre relancÃ©.
* Mais si tu modifies uniquement un fichier de ton code (pas `requirements.txt`), lâ€™Ã©tape 3 est **rÃ©utilisÃ©e depuis le cache**, donc pas besoin de rÃ©installer les dÃ©pendances ğŸ‰.

***

### ğŸ› ï¸ Bonnes pratiques pour optimiser le cache

#### 1. **Ordre des instructions = crucial**

Place les instructions **les moins susceptibles de changer** en haut de ton Dockerfile.\
ğŸ‘‰ Exemple :

* `apt-get install` (souvent stable) en haut,
* `COPY . .` (souvent modifiÃ©) en bas.

***

#### 2. **SÃ©parer la copie des dÃ©pendances**

```dockerfile
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
```

âœ… Ainsi, si tu modifies ton code mais pas `requirements.txt`, le cache garde lâ€™installation des dÃ©pendances â†’ build plus rapide.

***

#### 3. **Nettoyer intelligemment**

Toujours nettoyer (`apt-get clean`, `rm -rf /var/lib/apt/lists/*`) **dans la mÃªme couche** que lâ€™installation â†’ sinon tu gardes des fichiers inutiles dans le cache.

***

#### 4. **Utiliser `--target` pour reconstruire partiellement**

Avec les builds multi-Ã©tapes (`multi-stage builds`), tu peux cibler un stade prÃ©cis sans tout reconstruire :

```bash
docker build --target build-env -t myapp:build .
```

***

#### 5. **Forcer un build propre si nÃ©cessaire**

Si tu veux **ignorer le cache** (par ex. pour rÃ©cupÃ©rer les derniÃ¨res mises Ã  jour de sÃ©curitÃ©) :

```bash
docker build --no-cache -t myapp:latest .
```

***

### ğŸ“¸ Illustration conceptuelle

Imagine que tu cuisines ğŸ³ :

* Tu notes chaque Ã©tape (recette).
* Si tu refais la mÃªme recette demain, tu peux **rÃ©utiliser les Ã©tapes dÃ©jÃ  prÃ©parÃ©es** (sauce, lÃ©gumes coupÃ©s).
* Mais si tu changes un ingrÃ©dient (ex. `requirements.txt`), tu dois refaire toutes les Ã©tapes suivantes.

***

### âœ… RÃ©sumÃ©

* Docker construit image **instruction par instruction**, avec un cache pour accÃ©lÃ©rer.
* Lâ€™ordre du Dockerfile est **stratÃ©gique** pour optimiser la rÃ©utilisation du cache.
* SÃ©pare les dÃ©pendances et le code applicatif pour Ã©viter de tout reconstruire.
* Utilise `--no-cache` si tu veux forcer un build frais.

## ğŸ“Œ Bonnes pratiques de construction â€“ **Ã‰pingler les versions dâ€™images de base (Pin base image versions)**

***

### ğŸ§© Le problÃ¨me des tags "flottants"

Quand tu Ã©cris un Dockerfile avec une image de base, tu utilises gÃ©nÃ©ralement une **balise (tag)**, par ex. :

```dockerfile
# syntax=docker/dockerfile:1
FROM alpine:3.21
```

ğŸ‘‰ Or, les **tags sont mutables** :

* Aujourdâ€™hui, `alpine:3.21` peut pointer vers **3.21.1**
* Dans 3 mois, le mÃªme tag peut pointer vers **3.21.4**

Cela a deux consÃ©quences :

* âœ… Tu bÃ©nÃ©ficies automatiquement des **patchs de sÃ©curitÃ©**
* âŒ Mais tu nâ€™as **aucune garantie de reproductibilitÃ©** (ton image nâ€™est pas exactement la mÃªme selon la date du build)
* âŒ Pas dâ€™**audit trail clair** â†’ difficile de savoir quelle version exacte a Ã©tÃ© utilisÃ©e en prod

***

### ğŸ“Œ La solution : Ã©pingler par digest

Un digest (`sha256:...`) est un **identifiant unique et immuable** de lâ€™image.\
En lâ€™utilisant, tu garantis que ton build utilisera **toujours exactement la mÃªme image**, peu importe les mises Ã  jour cÃ´tÃ© Ã©diteur.

Exemple :

```dockerfile
# syntax=docker/dockerfile:1
FROM alpine:3.21@sha256:a8560b36e8b8210634f77d9f7f9efd7ffa463e380b75e2e74aff4511df3ef88c
```

ğŸ‘‰ Ici :

* Tu indiques toujours `alpine:3.21` pour la lisibilitÃ©
* Mais tu prÃ©cises le digest exact (`sha256:...`) qui ne changera jamais

***

### âš–ï¸ Avantages / InconvÃ©nients

#### âœ… Avantages

* **ReproductibilitÃ© totale** : mÃªme image Ã  chaque build
* **ChaÃ®ne dâ€™approvisionnement sÃ©curisÃ©e** : pas de remplacement surprise par lâ€™Ã©diteur
* **Audit clair** : tu sais exactement quelle version tourne

#### âŒ InconvÃ©nients

* **Maintenance plus lourde** : tu dois rechercher le digest Ã  chaque mise Ã  jour
* **Pas de mise Ã  jour automatique** â†’ tu peux rater des correctifs de sÃ©curitÃ© si tu nâ€™updates pas manuellement

***

### ğŸš€ Automatiser avec Docker Scout

Docker propose **Docker Scout** qui aide Ã  :

* VÃ©rifier si ton image de base est **Ã  jour**
* DÃ©tecter si ton digest est devenu obsolÃ¨te
* Automatiser les **mises Ã  jour via pull requests** â†’ Scout peut proposer un nouveau digest dans tes Dockerfiles

ğŸ‘‰ RÃ©sultat : tu combines le meilleur des deux mondes :

* ContrÃ´le total via digest
* Automatisation des updates avec audit trail (PRs claires et traÃ§ables)

***

### ğŸ“¸ Illustration conceptuelle

* Utiliser uniquement `alpine:3.21` = ğŸšª **porte qui change de clÃ© Ã  chaque fois** â†’ parfois tu entres, parfois non
* Utiliser `alpine:3.21@sha256:xxxx` = ğŸ”’ **clÃ© unique et fixe** â†’ tu es sÃ»r que câ€™est la bonne porte
* Utiliser `alpine:3.21@sha256:xxxx` + Docker Scout = ğŸ”‘ **clÃ© fixe**, mais avec un **majordome** qui tâ€™avertit quand une nouvelle serrure est disponible

***

### âœ… RÃ©sumÃ©

* Les tags (`alpine:3.21`) sont **mutables** â†’ bon pour les patchs auto, mauvais pour la reproductibilitÃ©
* Les digests (`sha256:...`) sont **immuables** â†’ parfaits pour la sÃ©curitÃ© et lâ€™audit
* Docker Scout permet dâ€™automatiser la mise Ã  jour des digests en gardant une **traÃ§abilitÃ© claire**

## ğŸ“Œ Build and test your images in CI

***

### ğŸ§© Pourquoi ?

* ğŸ›¡ï¸ **SÃ©curitÃ© & stabilitÃ©** : chaque changement est validÃ© automatiquement â†’ moins de risques dâ€™images corrompues ou vulnÃ©rables.
* ğŸ”„ **ReproductibilitÃ©** : les builds ne dÃ©pendent plus de ta machine locale ("it works on my machine").
* âš¡ **RapiditÃ©** : bugs et failles dÃ©tectÃ©s tÃ´t dans le cycle.
* ğŸ“¦ **Automatisation** : tes images sont construites, testÃ©es, et taguÃ©es dÃ¨s chaque commit/PR.

***

### âš™ï¸ Exemple avec GitHub Actions

Un workflow simple pour construire et tester une image :

```yaml
name: CI Docker Build

on:
  pull_request:
  push:
    branches: [ "main" ]

jobs:
  docker:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build image
        run: docker build -t myapp:test .

      - name: Run tests
        run: docker run --rm myapp:test pytest
```

#### ğŸ” DÃ©composition :

1. **Checkout** â†’ rÃ©cupÃ¨re ton code
2. **Setup Buildx** â†’ prÃ©pare lâ€™environnement multi-platform
3. **Login DockerHub** â†’ permet de push si besoin
4. **Build image** â†’ construit ton image avec un tag local `myapp:test`
5. **Run tests** â†’ lance tes tests unitaires/fonctionnels Ã  lâ€™intÃ©rieur du conteneur

***

### ğŸ·ï¸ Tagging automatique

Pour Ã©viter dâ€™Ã©craser les versions :

* Utilise le **SHA du commit** ou la **version du package** comme tag :

```yaml
- name: Build and push image
  run: |
    IMAGE=myorg/myapp:${{ github.sha }}
    docker build -t $IMAGE .
    docker push $IMAGE
```

ğŸ‘‰ Ã‡a garantit que chaque commit correspond Ã  une image traÃ§able.

***

### ğŸ“¸ Illustration conceptuelle

Imagine ta CI/CD comme une **chaÃ®ne de production automatisÃ©e** :

* ğŸ“¦ Tu poses ton code (commit/PR) sur le tapis
* ğŸ—ï¸ La chaÃ®ne construit lâ€™image
* ğŸ§ª Elle la teste
* âœ… Elle ne laisse passer que les images validÃ©es et traÃ§ables

***

### âœ… RÃ©sumÃ©

* ğŸ”„ IntÃ¨gre **build + test** de tes images dans ton pipeline CI/CD
* ğŸ·ï¸ Utilise des **tags uniques (SHA, version)** pour traÃ§abilitÃ©
* ğŸ›¡ï¸ Les images sont validÃ©es avant de passer en **prod**

## ğŸ“Œ Dockerfile instructions â€” bonnes pratiques

Chaque instruction (`FROM`, `RUN`, `COPY`, etc.) a ses **rÃ¨gles de bonne utilisation** pour Ã©viter :

* des images trop lourdes âš–ï¸,
* des builds trop longs ğŸŒ,
* des failles de sÃ©curitÃ© ğŸ”“,
* ou des Dockerfiles difficiles Ã  maintenir ğŸ› ï¸.

***

### âœ… Recommandations gÃ©nÃ©rales

1. **Sois explicite dans tes instructions**\
   â†’ utilise des tags prÃ©cis pour les images de base (`FROM ubuntu:24.04` plutÃ´t que `FROM ubuntu:latest`).
2. **RÃ©duis le nombre de couches**\
   â†’ combine les commandes `RUN` avec `&&` au lieu de multiplier les lignes.
3. **Trie & nettoie**\
   â†’ trie les paquets par ordre alphabÃ©tique et supprime les caches (`apt-get clean`, `rm -rf /var/lib/apt/lists/*`).
4. **SÃ©pare build et runtime**\
   â†’ multi-stage builds : un premier stage pour compiler, un second minimal pour exÃ©cuter.
5. **Minimise le contexte de build**\
   â†’ `.dockerignore` doit exclure logs, docs, node\_modules inutiles, etc.
6. **SÃ©curitÃ© avant tout**\
   â†’ Ã©vite `ADD` pour des fichiers locaux (utilise `COPY`) et nâ€™exÃ©cute pas en `root`.

***

### ğŸ“’ Exemple illustratif

Un mauvais Dockerfile ğŸ‘ :

```dockerfile
FROM ubuntu:latest
RUN apt-get update
RUN apt-get install -y curl git python3
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
CMD ["python3", "main.py"]
```

Un bon Dockerfile ğŸ‘ (multi-stage, optimisÃ©, sÃ©curisÃ©) :

```dockerfile
# Ã‰tape build
FROM python:3.11-slim AS builder
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Ã‰tape runtime
FROM python:3.11-slim
WORKDIR /app
COPY --from=builder /usr/local /usr/local
COPY . .
USER 1001
CMD ["python", "main.py"]
```

#### âœ… Points forts :

* `python:3.11-slim` â†’ base image minimale
* multi-stage â†’ runtime allÃ©gÃ©
* `--no-cache-dir` â†’ pas de dÃ©pendances inutiles
* `USER 1001` â†’ pas root

***

### ğŸ’¡ Outils utiles

* **Docker VS Code Extension** â†’\
  ğŸ” linting + autocomplÃ©tion + scan de vulnÃ©rabilitÃ©s directement dans ton IDE.
* **Hadolint** â†’ linter Dockerfile en CLI.

## ğŸ—ï¸ Instruction `FROM`

La directive **`FROM`** dÃ©finit lâ€™**image de base** sur laquelle ton image Docker sera construite.\
Chaque image Docker (sauf `FROM scratch`) est construite Ã  partir dâ€™une autre image.

***

### âœ… Bonnes pratiques pour `FROM`

#### 1. Utiliser des images **officielles et maintenues**

* Favoriser les images officielles de Docker Hub.
* Exemple : `FROM ubuntu:24.04`, `FROM node:20-alpine`, `FROM python:3.11-slim`.

#### 2. PrÃ©fÃ©rer les variantes **lÃ©gÃ¨res**

* `alpine` : trÃ¨s petite (â‰ˆ 6 MB), distribution Linux complÃ¨te â†’ rapide et peu de surface dâ€™attaque.
* `slim` : un compromis entre taille et compatibilitÃ©.

Exemple :

```dockerfile
FROM node:20-alpine
```

#### 3. Ã‰viter `latest`

* `FROM ubuntu:latest` est dangereux car mutable â†’ ton build peut casser du jour au lendemain.
* Toujours **pinner une version** (`FROM ubuntu:24.04` ou mieux avec un **digest SHA256**).

Exemple avec digest :

```dockerfile
FROM alpine:3.21@sha256:a8560b36e8b8210634f77d9f7f9efd7ffa463e380b75e2e74aff4511df3ef88c
```

#### 4. Utiliser `scratch` pour les images minimales

* `scratch` est une image vide.
* TrÃ¨s utile pour les binaires statiques (Go, Rust, C).

Exemple :

```dockerfile
FROM scratch
COPY mybinary /
CMD ["/mybinary"]
```

#### 5. Multi-stage builds

* On peut utiliser **plusieurs `FROM`** dans un mÃªme Dockerfile.
* Utile pour sÃ©parer la compilation et le runtime.

Exemple :

```dockerfile
# Ã‰tape build
FROM golang:1.22-alpine AS builder
WORKDIR /app
COPY . .
RUN go build -o myapp .

# Ã‰tape runtime minimal
FROM alpine:3.21
COPY --from=builder /app/myapp /usr/local/bin/
CMD ["myapp"]
```

***

### ğŸ“’ Illustration conceptuelle

Imaginons ton image comme un **sandwich** ğŸ¥ª :

* `FROM` = **le pain** (la base : Ubuntu, Alpine, etc.)
* `RUN`, `COPY` = **les ingrÃ©dients** que tu ajoutes
* `CMD`/`ENTRYPOINT` = **comment tu le manges** (le processus de dÃ©marrage).

## ğŸ·ï¸ Instruction `LABEL`

Les **labels** sont des **mÃ©tadonnÃ©es** que tu ajoutes Ã  ton image Docker.\
Ils ne changent pas le fonctionnement de ton conteneur, mais servent Ã  **documenter**, **organiser** et **automatiser** la gestion de tes images.

***

### âœ… Bonnes pratiques pour `LABEL`

#### 1. DÃ©finir des mÃ©tadonnÃ©es utiles

Quelques cas dâ€™usage :

*   **Versioning** :

    ```dockerfile
    LABEL version="1.0.0"
    ```
*   **Auteur / Mainteneur** :

    ```dockerfile
    LABEL maintainer="john.doe@example.com"
    ```
*   **Projet & Vendor** :

    ```dockerfile
    LABEL org.opencontainers.image.title="MyApp" \
          org.opencontainers.image.vendor="ACME Corp"
    ```
*   **Licence & dÃ©pÃ´t source** :

    ```dockerfile
    LABEL org.opencontainers.image.licenses="MIT" \
          org.opencontainers.image.source="https://github.com/acme/myapp"
    ```

ğŸ‘‰ **Astuce** : privilÃ©gie les labels du **standard OCI (Open Containers Initiative)** pour assurer une meilleure compatibilitÃ© avec les outils :\
ğŸ”— [SpÃ©cification OCI Annotations](https://github.com/opencontainers/image-spec/blob/main/annotations.md)

Exemples clÃ©s standards :

* `org.opencontainers.image.title`
* `org.opencontainers.image.description`
* `org.opencontainers.image.url`
* `org.opencontainers.image.source`
* `org.opencontainers.image.version`
* `org.opencontainers.image.licenses`

***

#### 2. Syntaxes acceptÃ©es

*   **Un label par ligne** :

    ```dockerfile
    LABEL com.example.version="0.0.1-beta"
    LABEL vendor="ACME Incorporated"
    ```
*   **Plusieurs labels sur une ligne** :

    ```dockerfile
    LABEL com.example.version="0.0.1-beta" com.example.release-date="2015-02-12"
    ```
*   **Labels multi-lignes (lisibilitÃ© ++)** :

    ```dockerfile
    LABEL vendor="ACME Incorporated" \
          com.example.is-beta="" \
          com.example.is-production="" \
          com.example.version="0.0.1-beta" \
          com.example.release-date="2015-02-12"
    ```

âš ï¸ Attention :

*   Si une valeur contient des **espaces**, il faut la **citer** ou **Ã©chapper** :

    ```dockerfile
    LABEL vendor="ZENITH Incorporated"
    # ou
    LABEL vendor=ZENITH\ Incorporated
    ```
* Les guillemets intÃ©rieurs doivent Ãªtre Ã©chappÃ©s.

***

#### 3. Visualiser les labels

AprÃ¨s un build :

```bash
docker inspect <image_id> --format '{{json .Config.Labels}}' | jq
```

Exemple de sortie :

```json
{
  "version": "1.0.0",
  "maintainer": "john.doe@example.com",
  "org.opencontainers.image.source": "https://github.com/acme/myapp"
}
```

***

### ğŸ“’ Illustration

Imagine que ton image Docker soit une **boÃ®te de conserve** ğŸ¥« :

* Le **contenu** = ton app + dÃ©pendances
* Les **labels** = lâ€™**Ã©tiquette** sur la boÃ®te â†’ infos sur la recette, date de production, version, fabricant.\
  Sans Ã©tiquette, tu dois ouvrir la boÃ®te pour savoir ce quâ€™il y a dedans ğŸ˜….

## âš™ï¸ Instruction `RUN`

Lâ€™instruction **`RUN`** exÃ©cute une commande dans une nouvelle **couche intermÃ©diaire** de lâ€™image Docker.\
ğŸ‘‰ Elle est utilisÃ©e pour **installer des paquets**, **configurer des dÃ©pendances**, ou **prÃ©parer lâ€™environnement** de ton image.

***

### âœ¨ Bonnes pratiques

#### ğŸ”¹ 1. Rendre les commandes lisibles

Quand les commandes sont longues, dÃ©coupe-les sur **plusieurs lignes** avec `\` :

```dockerfile
RUN apt-get update && apt-get install -y --no-install-recommends \
    package-bar \
    package-baz \
    package-foo
```

ğŸ’¡ Astuce : tu peux aussi utiliser les **here documents** (`<<EOF`) pour enchaÃ®ner plusieurs commandes sans utiliser `&&` :

```dockerfile
RUN <<EOF
apt-get update
apt-get install -y --no-install-recommends \
    package-bar \
    package-baz \
    package-foo
EOF
```

***

#### ğŸ”¹ 2. Bien utiliser `apt-get`

Sur les images Debian/Ubuntu, la commande **`apt-get`** est courante, mais il faut respecter certaines rÃ¨gles :

âœ… Toujours combiner `apt-get update` et `apt-get install` dans la **mÃªme commande** :

```dockerfile
RUN apt-get update && apt-get install -y --no-install-recommends curl
```

âŒ Mauvais exemple (risque de cache obsolÃ¨te et paquets dÃ©passÃ©s) :

```dockerfile
RUN apt-get update
RUN apt-get install -y curl
```

ğŸ‘‰ Pourquoi ? Parce que Docker met en cache chaque `RUN`. Si tu ajoutes un paquet plus tard, lâ€™Ã©tape `apt-get update` peut Ãªtre rÃ©utilisÃ©e depuis le cache, ce qui fait que tes paquets ne seront **jamais mis Ã  jour**.

***

#### ğŸ”¹ 3. Utiliser le **cache busting** et le **version pinning**

* **Cache busting** : permet de forcer Docker Ã  rÃ©-exÃ©cuter `apt-get update` â†’ garantit des paquets frais.
*   **Version pinning** : installe une **version prÃ©cise** dâ€™un paquet pour Ã©viter les surprises :

    ```dockerfile
    RUN apt-get update && apt-get install -y --no-install-recommends \
        s3cmd=1.1.* \
        && rm -rf /var/lib/apt/lists/*
    ```

***

#### ğŸ”¹ 4. Nettoyer aprÃ¨s installation

âš¡ Pour rÃ©duire la taille de lâ€™image, supprime le cache `apt` aprÃ¨s installation :

```dockerfile
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*
```

ğŸ’¡ Les images officielles Debian/Ubuntu exÃ©cutent dÃ©jÃ  `apt-get clean`, mais supprimer `/var/lib/apt/lists` reste une bonne pratique.

***

#### ğŸ”¹ 5. GÃ©rer les pipes (`|`)

Par dÃ©faut, Docker utilise `/bin/sh -c`.\
ğŸ‘‰ ProblÃ¨me : dans une commande avec un **pipe (`|`)**, seul le **dernier programme** dÃ©termine le succÃ¨s.

Exemple dangereux âŒ :

```dockerfile
RUN wget -O - https://some.site | wc -l > /number
```

ğŸ‘‰ Ici, mÃªme si `wget` Ã©choue, lâ€™Ã©tape rÃ©ussit si `wc -l` sâ€™exÃ©cute.

âœ… Solution : activer `pipefail` :

```dockerfile
RUN set -o pipefail && wget -O - https://some.site | wc -l > /number
```

Si ton shell ne supporte pas `pipefail` (ex. `dash` sur Debian), utilise la forme **exec** :

```dockerfile
RUN ["/bin/bash", "-c", "set -o pipefail && wget -O - https://some.site | wc -l > /number"]
```

***

### ğŸ“’ Exemple complet et propre

```dockerfile
# syntax=docker/dockerfile:1
FROM ubuntu:24.04

RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    git \
    make \
    && rm -rf /var/lib/apt/lists/*
```

â¡ï¸ Ici :

* `apt-get update` et `install` sont regroupÃ©s âœ…
* les paquets sont listÃ©s ligne par ligne (lisibilitÃ© + pas de doublons) âœ…
* `--no-install-recommends` limite les dÃ©pendances inutiles âœ…
* suppression du cache apt (image plus lÃ©gÃ¨re) âœ…

***

âš¡ **RÃ©sumÃ©** :

* DÃ©coupe tes `RUN` longs â†’ lisibilitÃ© ğŸ“–
* Toujours combiner `update` + `install` â†’ Ã©viter les caches obsolÃ¨tes ğŸ›‘
* Version pinning si tu veux de la stabilitÃ© ğŸ”’
* Nettoyer aprÃ¨s install â†’ images plus petites ğŸª¶
* Attention aux pipes â†’ utilise `pipefail` âš¡

## âš™ï¸ Instruction `CMD`

ğŸ‘‰ Lâ€™instruction **`CMD`** dÃ©finit la **commande par dÃ©faut** exÃ©cutÃ©e lorsquâ€™un conteneur est lancÃ© Ã  partir dâ€™une image.

* Elle peut inclure un **programme** + **arguments**,
* Ou simplement une **commande interactive** (ex. un shell).
* Elle est **surchargÃ©e** si lâ€™utilisateur passe une commande lors du `docker run`.

***

### ğŸ”¹ Bonnes pratiques avec `CMD`

#### 1. Utiliser la forme **exec** (JSON array) âœ…

La meilleure pratique est dâ€™Ã©crire :

```dockerfile
CMD ["executable", "param1", "param2"]
```

Pourquoi ?

* Pas dâ€™appel implicite Ã  `/bin/sh -c` (donc plus sÃ»r).
* Gestion plus fiable des signaux (SIGTERM, SIGINT).

Exemple (service Apache qui reste au premier plan) :

```dockerfile
CMD ["apache2", "-DFOREGROUND"]
```

***

#### 2. Usage pour les services ğŸ–¥ï¸

Si ton image est dÃ©diÃ©e Ã  un service (web, API, worker, etc.), `CMD` doit lancer **ce service**.\
â¡ï¸ Cela assure que le conteneur fait â€œce pourquoi il a Ã©tÃ© conÃ§uâ€.

***

#### 3. Usage pour les environnements interactifs ğŸš

Pour des images servant de **base interactive** (langages, shellsâ€¦), on utilise `CMD` pour fournir une **console prÃªte Ã  lâ€™emploi**.

Exemples :

```dockerfile
CMD ["perl", "-de0"]
CMD ["python"]
CMD ["php", "-a"]
```

Ainsi :

```bash
docker run -it python
```

â¡ï¸ Te donne directement une **REPL Python** utilisable.

***

#### 4. Cas Ã  Ã©viter ğŸš«

Il est **rarement recommandÃ©** dâ€™utiliser `CMD` uniquement comme une **liste de paramÃ¨tres** en complÃ©ment dâ€™`ENTRYPOINT` :

```dockerfile
ENTRYPOINT ["nginx"]
CMD ["-g", "daemon off;"]
```

ğŸ‘‰ Ce pattern peut Ãªtre utile dans des cas avancÃ©s, mais il devient **confus** si tes utilisateurs ne savent pas comment `ENTRYPOINT` et `CMD` interagissent.

***

### ğŸ”¹ Interaction avec `docker run` âš¡

* Si lâ€™utilisateur ne passe **aucune commande**, Docker utilise **`CMD`**.
* Si une commande est passÃ©e, **elle remplace `CMD`**.

Exemple :

```dockerfile
# syntax=docker/dockerfile:1
FROM ubuntu
CMD ["echo", "Hello from CMD"]
```

```bash
docker run myimage
# â affiche "Hello from CMD"

docker run myimage echo "Overridden"
# â affiche "Overridden"
```

***

### ğŸ“’ Exemple complet

Image Python prÃªte Ã  lâ€™emploi :

```dockerfile
# syntax=docker/dockerfile:1
FROM python:3.11-slim

WORKDIR /app
COPY . .

# Lance Python en mode interactif par dÃ©faut
CMD ["python"]
```

Utilisation :

```bash
docker run -it mypython
# â Ouvre un shell Python interactif
```

***

âœ… **RÃ©sumÃ© :**

* Toujours prÃ©fÃ©rer la forme **exec** (`["..."]`).
* `CMD` = **commande par dÃ©faut**, mais **remplaÃ§able** avec `docker run`.
* IdÃ©al pour :
  * Services (ex: `CMD ["apache2", "-DFOREGROUND"]`)
  * Environnements interactifs (`CMD ["python"]`)
* Ã‰vite dâ€™utiliser `CMD` uniquement comme arguments dâ€™un `ENTRYPOINT`, sauf si nÃ©cessaire.

## âš“ Instruction `EXPOSE`

ğŸ‘‰ **`EXPOSE`** indique les **ports** sur lesquels le conteneur **Ã©coute** pour accepter des connexions.\
Câ€™est une **mÃ©tadonnÃ©e dÃ©clarative** dans ton `Dockerfile`, et non une rÃ¨gle de pare-feu ou un mappage automatique de ports.

***

### ğŸ”¹ Comment Ã§a marche ?

Exemple classique avec Apache :

```dockerfile
EXPOSE 80
```

â¡ï¸ Cela documente que ton conteneur Ã©coute sur le port **80** (HTTP).

Autres exemples :

* MongoDB â†’ `EXPOSE 27017`
* PostgreSQL â†’ `EXPOSE 5432`
* Application custom sur port 8080 â†’ `EXPOSE 8080`

***

### ğŸ”¹ Attention : `EXPOSE` â‰  accÃ¨s externe âŒ

* `EXPOSE` **ne publie pas** le port sur ta machine hÃ´te.
* Pour rendre le service accessible depuis lâ€™extÃ©rieur, il faut mapper le port avec `-p` ou `--publish` :

```bash
docker run -p 8080:80 my-apache
```

â¡ï¸ Ici, le **port 8080** de ta machine hÃ´te est reliÃ© au **port 80** du conteneur.

***

### ğŸ”¹ Utilisation dans les rÃ©seaux Docker ğŸŒ

Quand tu relies des conteneurs entre eux (via des **networks**), lâ€™instruction `EXPOSE` sert surtout de **documentation** et de convention.\
Docker peut utiliser ces mÃ©tadonnÃ©es pour :

* CrÃ©er des **variables dâ€™environnement** (ex: `MYSQL_PORT_3306_TCP`).
* Aider Ã  lâ€™**auto-configuration** entre conteneurs liÃ©s.

***

### ğŸ“’ Exemple complet

Un serveur Node.js :

```dockerfile
# syntax=docker/dockerfile:1
FROM node:20

WORKDIR /app
COPY . .

RUN npm install
EXPOSE 3000

CMD ["npm", "start"]
```

ExÃ©cution :

```bash
docker build -t my-node-app .
docker run -p 8080:3000 my-node-app
```

â¡ï¸ Ton appli Ã©coute sur **3000** dans le conteneur, mais est exposÃ©e sur **8080** cÃ´tÃ© hÃ´te.

***

âœ… **RÃ©sumÃ© :**

* `EXPOSE` documente les **ports Ã©coutÃ©s** par lâ€™application.
* Il **ne publie pas automatiquement** le port â†’ `-p` ou `--publish` sont nÃ©cessaires.
* Sert surtout de convention + interopÃ©rabilitÃ© entre conteneurs.

## âš™ï¸ Instruction `ENV`

ğŸ‘‰ Lâ€™instruction **`ENV`** dÃ©finit des **variables dâ€™environnement** dans ton image.\
Ces variables sont ensuite disponibles :

* au moment de la construction de lâ€™image ğŸ—ï¸,
* dans le conteneur au moment de lâ€™exÃ©cution â–¶ï¸.

***

### ğŸ”¹ Cas dâ€™usage courants

#### 1. Mettre Ã  jour le `PATH` ğŸ”

Tu peux rendre un logiciel accessible sans prÃ©ciser son chemin complet :

```dockerfile
ENV PATH=/usr/local/nginx/bin:$PATH
```

â¡ï¸ Ainsi, `CMD ["nginx"]` fonctionne directement âœ….

***

#### 2. DÃ©finir des variables spÃ©cifiques aux services ğŸ—„ï¸

Exemple avec **Postgres** :

```dockerfile
ENV PGDATA=/var/lib/postgresql/data
```

Cela permet au service de connaÃ®tre son rÃ©pertoire de donnÃ©es.

***

#### 3. Centraliser des **versions de logiciels** ğŸ“¦

Au lieu de â€œhardcoderâ€ une version Ã  plusieurs endroits, tu la dÃ©finis une fois :

```dockerfile
ENV PG_MAJOR=9.3
ENV PG_VERSION=9.3.4

RUN curl -SL https://example.com/postgres-$PG_VERSION.tar.xz \
    | tar -xJC /usr/src/postgres

ENV PATH=/usr/local/postgres-$PG_MAJOR/bin:$PATH
```

ğŸ’¡ Câ€™est comme utiliser des **constantes dans un programme** : un seul changement met Ã  jour toute lâ€™image.

***

### ğŸ”¹ âš ï¸ Attention aux couches Docker

Chaque `ENV` crÃ©e une **nouvelle couche intermÃ©diaire**, tout comme `RUN`.\
ğŸ‘‰ MÃªme si tu `unset` une variable plus tard, **elle reste stockÃ©e dans lâ€™historique de lâ€™image**.

Exemple :

```dockerfile
FROM alpine
ENV ADMIN_USER="mark"
RUN echo $ADMIN_USER > ./mark
RUN unset ADMIN_USER
```

Test :

```bash
docker run --rm test sh -c 'echo $ADMIN_USER'
```

â¡ï¸ RÃ©sultat : `mark` (la variable persiste malgrÃ© le unset âš ï¸).

***

### ğŸ”¹ Solution : tout gÃ©rer dans une seule couche ğŸ›¡ï¸

Pour Ã©viter les fuites de variables sensibles (comme des mots de passe), il faut **dÃ©finir, utiliser et unset** dans la **mÃªme commande `RUN`** :

```dockerfile
FROM alpine
RUN export ADMIN_USER="mark" \
    && echo $ADMIN_USER > ./mark \
    && unset ADMIN_USER
CMD sh
```

Cette fois :

```bash
docker run --rm test sh -c 'echo $ADMIN_USER'
```

â¡ï¸ RÃ©sultat : **rien**, la variable est bien nettoyÃ©e âœ….

***

### ğŸ“’ Exemple complet

Un `Dockerfile` qui installe une app avec version configurable :

```dockerfile
# syntax=docker/dockerfile:1
FROM node:20

ENV APP_VERSION=1.2.0
ENV APP_PATH=/usr/local/app

WORKDIR $APP_PATH

RUN curl -sL https://example.com/myapp-$APP_VERSION.tar.gz | tar -xz -C $APP_PATH

ENV PATH=$APP_PATH/bin:$PATH

CMD ["myapp"]
```

ğŸ’¡ Ici :

* `APP_VERSION` = facile Ã  changer quand une nouvelle version sort
* `APP_PATH` = centralisÃ© â†’ moins dâ€™erreurs
* `PATH` = mis Ã  jour â†’ la commande `myapp` fonctionne directement

***

### âœ… RÃ©sumÃ©

* `ENV` = dÃ©finit des variables dâ€™environnement pour la **construction** et lâ€™**exÃ©cution**.
* Sert Ã  : mettre Ã  jour le `PATH`, configurer des services, centraliser les versions.
* âš ï¸ Attention : les variables persistent dans lâ€™historique â†’ ne pas stocker de secrets.
* Pour protÃ©ger des donnÃ©es sensibles â†’ dÃ©finir, utiliser et unset dans **une seule couche**.

## âš–ï¸ `ADD` vs `COPY`

### ğŸ”¹ **COPY**

* **Usage principal** : copier **des fichiers locaux** du _build context_ (ton projet) â†’ vers le conteneur.
* Supporte aussi la copie entre **multi-stage builds** (`COPY --from=builder ...`).
* Câ€™est la commande **par dÃ©faut** pour presque tous les cas.

ğŸ‘‰ Exemple simple :

```dockerfile
COPY package.json /app/
```

ğŸ‘‰ Exemple multi-stage :

```dockerfile
FROM node:20 AS builder
WORKDIR /app
COPY . .
RUN npm install && npm run build

FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
```

***

### ğŸ”¹ **ADD**

* Fait tout ce que `COPY` fait, **plus deux fonctionnalitÃ©s supplÃ©mentaires** :
  1. **TÃ©lÃ©charger** des fichiers depuis une **URL distante (HTTP/HTTPS/Git)**
  2. **DÃ©compresser automatiquement** les fichiers `.tar` quand ils proviennent du build context

ğŸ‘‰ Exemple avec tÃ©lÃ©chargement direct :

```dockerfile
ARG DOTNET_VERSION=8.0.0-preview.6.23329.7
ADD --checksum=sha256:270d731bd08040c6a3228115de1f74b91cf441c584139ff8f8f6503447cebdbb \
    https://dotnetcli.azureedge.net/dotnet/Runtime/$DOTNET_VERSION/dotnet-runtime-$DOTNET_VERSION-linux-arm64.tar.gz /dotnet.tar.gz
```

ğŸ‘‰ Exemple avec extraction auto dâ€™un `.tar` :

```dockerfile
ADD app.tar.gz /app/
```

Ici, le contenu est directement **dÃ©compressÃ©** dans `/app`.

***

### ğŸ”¹ âš¡ Comparaison rapide

| Instruction | FonctionnalitÃ©s principales                                   | Cas recommandÃ©          |
| ----------- | ------------------------------------------------------------- | ----------------------- |
| **COPY**    | Copier fichiers/dossiers depuis le contexte ou un autre stage | **Toujours par dÃ©faut** |
| **ADD**     | + TÃ©lÃ©chargement URL                                          | + Extraction `.tar`     |

***

### ğŸ”¹ Optimisation : `RUN --mount` au lieu de `COPY`

Si tu veux juste utiliser un fichier temporairement (ex. `requirements.txt` pour un `pip install`), pas besoin de le copier dans lâ€™image â†’ tu peux **le monter** juste pour une commande :

```dockerfile
RUN --mount=type=bind,source=requirements.txt,target=/tmp/requirements.txt \
    pip install --requirement /tmp/requirements.txt
```

ğŸ‘‰ Avantages :

* Pas stockÃ© dans lâ€™image finale
* Pas de pollution de couches
* Plus rapide âš¡

***

### âœ… RÃ¨gle de base

* **Toujours utiliser `COPY`** sauf si tu as un vrai besoin de `ADD`.
* Si tu tÃ©lÃ©charges depuis le net â†’ `ADD` est mieux que `wget/curl` (cache + checksum).
* Si tu as besoin dâ€™extraire un `.tar` â†’ `ADD`.
* Pour les fichiers temporaires â†’ prÃ©fÃ¨re `RUN --mount`.

## ğŸ”¹ ENTRYPOINT

* DÃ©finit **le binaire ou script principal** que ton conteneur doit exÃ©cuter.
* Fait en sorte que ton image puisse Ãªtre exÃ©cutÃ©e **comme si câ€™Ã©tait ce binaire lui-mÃªme**.
* Ne peut pas Ãªtre facilement remplacÃ© Ã  lâ€™exÃ©cution (sauf avec `--entrypoint`).

ğŸ‘‰ Exemple minimal :

```dockerfile
ENTRYPOINT ["s3cmd"]
CMD ["--help"]
```

* Ici, `ENTRYPOINT` fige `s3cmd` comme programme principal.
* `CMD ["--help"]` fournit les **arguments par dÃ©faut**.
* Donc :
  * `docker run s3cmd` â†’ exÃ©cute `s3cmd --help`
  * `docker run s3cmd ls s3://bucket` â†’ exÃ©cute `s3cmd ls s3://bucket`

***

## ğŸ”¹ ENTRYPOINT avec script dâ€™initialisation

TrÃ¨s utile quand :

* Tu dois prÃ©parer lâ€™environnement avant de lancer ton programme (changer les droits, init DB, etc.).
* Tu veux que le conteneur soit **polyvalent** (par dÃ©faut il lance ton service, mais il peut aussi exÃ©cuter dâ€™autres commandes).

ğŸ‘‰ Exemple : **Postgres officiel**

```dockerfile
COPY ./docker-entrypoint.sh /
ENTRYPOINT ["/docker-entrypoint.sh"]
CMD ["postgres"]
```

#### `docker-entrypoint.sh`

```bash
#!/bin/bash
set -e

if [ "$1" = 'postgres' ]; then
    chown -R postgres "$PGDATA"

    if [ -z "$(ls -A "$PGDATA")" ]; then
        gosu postgres initdb
    fi

    exec gosu postgres "$@"
fi

exec "$@"
```

#### Ce que Ã§a donne :

* `docker run postgres` â†’ lance Postgres normalement
* `docker run postgres postgres --help` â†’ lance Postgres avec `--help`
* `docker run -it postgres bash` â†’ ouvre Bash Ã  la place

ğŸ‘‰ Pourquoi Ã§a marche ?\
Le script utilise `exec "$@"` â†’ ce qui fait que **le processus final devient le PID 1 du conteneur**.\
Cela permet au programme (Postgres ici) de recevoir directement les **signaux Unix** (`SIGTERM`, `SIGINT`â€¦), indispensables pour un arrÃªt propre.

***

## ğŸ”¹ ENTRYPOINT vs CMD : la rÃ¨gle dâ€™or

* **ENTRYPOINT = ce que fait le conteneur (binaire/script principal)**
* **CMD = arguments par dÃ©faut (ou fallback)**

ğŸ‘‰ Exemple dâ€™usage typique :

```dockerfile
ENTRYPOINT ["python"]
CMD ["app.py"]
```

* `docker run myapp` â†’ `python app.py`
* `docker run myapp -m http.server` â†’ `python -m http.server`

***

## âœ… Bonnes pratiques

1. Utilise **ENTRYPOINT en mode exec** (`["prog", "arg1", ...]`) â†’ Ã©vite `/bin/sh -c` qui complique la gestion des signaux.
2. Combine avec `CMD` pour des **arguments par dÃ©faut** mais flexibles.
3. Si tu dois faire un prÃ©-traitement (init DB, migration, config), passe par un **script wrapper** en `ENTRYPOINT`.
4. Utilise `exec` dans le script pour que ton vrai programme devienne **PID 1**.

## ğŸ”¹ Quâ€™est-ce que `VOLUME` ?

La directive `VOLUME` dans un `Dockerfile` dÃ©clare un ou plusieurs chemins dans le conteneur comme **points de montage persistants**.

ğŸ‘‰ Cela signifie :

* Les fichiers Ã©crits dans ce chemin **ne font plus partie de lâ€™image**.
* Ils sont stockÃ©s dans un **volume Docker** (ou un bind mount si tu le rediriges manuellement).
* MÃªme si le conteneur est supprimÃ©, le volume **persiste**.

***

## ğŸ”¹ Exemple basique

```dockerfile
FROM mysql:8.0
VOLUME ["/var/lib/mysql"]
```

* Ici, MySQL stocke ses donnÃ©es dans `/var/lib/mysql`.
* GrÃ¢ce au `VOLUME`, les donnÃ©es sont **sÃ©parÃ©es de lâ€™image**.
* Si tu reconstruis ou supprimes le conteneur â†’ tes donnÃ©es restent.

***

## ğŸ”¹ Pourquoi utiliser `VOLUME` ?

âœ… Pour tout ce qui est **mutable** (peut changer aprÃ¨s le build) :

* Bases de donnÃ©es (`/var/lib/mysql`, `/var/lib/postgresql/data`)
* Configurations modifiables par lâ€™utilisateur
* Logs gÃ©nÃ©rÃ©s par lâ€™application

âœ… Pour tout ce qui est **user-serviceable** (que lâ€™utilisateur doit gÃ©rer/persister).

âŒ Ã€ Ã©viter pour les fichiers **statiques** (code source, binaires), qui doivent rester dans lâ€™image.

***

## ğŸ”¹ Utilisation en pratique

#### 1. DÃ©clarer dans le `Dockerfile`

```dockerfile
VOLUME ["/data"]
```

#### 2. VÃ©rifier avec `docker inspect`

```bash
docker inspect mycontainer
```

â†’ tu verras que `/data` pointe vers un volume gÃ©rÃ© par Docker (`/var/lib/docker/volumes/...`).

#### 3. Monter un volume explicite

```bash
docker run -d -v mydata:/data myimage
```

#### 4. Ou utiliser un bind mount

```bash
docker run -d -v $(pwd)/data:/data myimage
```

***

## ğŸ”¹ Exemple concret : PostgreSQL

```dockerfile
FROM postgres:16
VOLUME ["/var/lib/postgresql/data"]
```

* Les donnÃ©es sont persistÃ©es dans `/var/lib/docker/volumes/...`.
*   Tu peux aussi binder ton dossier local si tu veux manipuler les fichiers directement :

    ```bash
    docker run -v $(pwd)/pgdata:/var/lib/postgresql/data postgres:16
    ```

***

## ğŸ”¹ Attention aux piÃ¨ges

1. **CrÃ©ation implicite de volumes**
   * Si tu utilises `VOLUME` dans le Dockerfile, Docker crÃ©e automatiquement un volume anonyme si tu nâ€™en fournis pas un.
   * RÃ©sultat : tu te retrouves parfois avec des volumes orphelins qui remplissent ton disque.
   * ğŸ‘‰ Bonne pratique : utiliser des **volumes nommÃ©s** (`-v mydata:/data`) ou un orchestrateur (Compose, Kubernetes).
2. **ImmutabilitÃ© de lâ€™image**
   * Tu ne peux pas modifier un `VOLUME` dÃ©fini dans lâ€™image sans reconstruire lâ€™image.
3. **Backup / restauration**
   * Comme les donnÃ©es sont hors de lâ€™image, il faut penser Ã  gÃ©rer les sauvegardes des volumes sÃ©parÃ©ment.

***

## âœ… RÃ¨gle dâ€™or

ğŸ‘‰ **`VOLUME` = pour la persistance des donnÃ©es dynamiques**\
ğŸ‘‰ **`COPY`/`ADD` = pour les fichiers statiques**

## ğŸ”¹ Pourquoi `USER` ?

Par dÃ©faut, un conteneur dÃ©marre sous lâ€™utilisateur **root**.\
ğŸ‘‰ Ce nâ€™est pas idÃ©al, car si un attaquant exploite ton conteneur, il a potentiellement les droits **root** dans le conteneur (et parfois sur lâ€™hÃ´te en cas de faille).

â¡ï¸ **Bonne pratique :** exÃ©cuter ton application avec un utilisateur **non-root**, sauf si elle a absolument besoin de privilÃ¨ges.

***

## ğŸ”¹ Exemple basique

```dockerfile
FROM postgres:16

# CrÃ©er un groupe et un utilisateur non-root
RUN groupadd -r postgres && useradd --no-log-init -r -g postgres postgres

# DÃ©finir l'utilisateur Ã  utiliser
USER postgres

# DÃ©marrer le service
CMD ["postgres"]
```

ğŸ‘‰ Ici, le service **Postgres** tourne sous lâ€™utilisateur `postgres` et non `root`.

***

## ğŸ”¹ DÃ©tails importants

#### 1. UID/GID explicite

* Par dÃ©faut, `useradd` attribue le prochain UID/GID disponible.
* Mais Ã§a peut varier entre builds â†’ **non dÃ©terministe**.
* Donc, si tu veux de la stabilitÃ© (CI/CD, sÃ©curitÃ©, Kubernetes), dÃ©finis-les :

```dockerfile
RUN groupadd -g 999 postgres && useradd -u 999 -g postgres postgres
```

***

#### 2. Bug avec `useradd` et UID Ã©levÃ©

âš ï¸ Avec certains UID/GID trÃ¨s grands, un **bug dans `tar` de Go** remplit `/var/log/faillog` avec des `\0` â†’ disque saturÃ©.\
ğŸ‘‰ Solution : ajouter `--no-log-init` comme dans lâ€™exemple :

```dockerfile
RUN useradd --no-log-init -u 999 -g postgres postgres
```

***

#### 3. Pas de `sudo` âŒ

* Installer `sudo` est inutile dans un conteneur (pas dâ€™interactivitÃ© ni gestion dâ€™accÃ¨s complexe).
* Ã‡a complique et introduit des problÃ¨mes avec les TTY et signaux.

ğŸ‘‰ Utilise plutÃ´t **`gosu`** ou **`su-exec`** si tu dois dÃ©marrer un process root, puis basculer vers un user non-root :

```dockerfile
RUN apt-get update && apt-get install -y gosu
COPY docker-entrypoint.sh /usr/local/bin/
ENTRYPOINT ["docker-entrypoint.sh"]
```

Dans `docker-entrypoint.sh` :

```bash
#!/bin/bash
if [ "$1" = 'postgres' ]; then
    exec gosu postgres "$@"
fi
exec "$@"
```

***

#### 4. Ã‰viter les allers-retours de `USER`

Changer plusieurs fois entre root/non-root = complexitÃ© et couches inutiles.\
ğŸ‘‰ Regroupe la configuration root **avant** le `USER` final.

Exemple **mauvais** âŒ :

```dockerfile
USER appuser
RUN echo "test" > /tmp/test
USER root
RUN apt-get install -y curl
USER appuser
```

Exemple **propre** âœ… :

```dockerfile
RUN apt-get install -y curl && \
    groupadd -g 1001 app && useradd -u 1001 -g app app
USER app
```

***

## ğŸ”¹ RÃ©sumÃ© des bonnes pratiques `USER`

âœ”ï¸ Toujours utiliser un **utilisateur non-root** si possible.\
âœ”ï¸ DÃ©finir **UID/GID explicites** pour reproductibilitÃ©.\
âœ”ï¸ Utiliser `--no-log-init` pour Ã©viter le bug Go/tar.\
âœ”ï¸ Pas de `sudo`, prÃ©fÃ©rer `gosu` ou `su-exec`.\
âœ”ï¸ Ne pas multiplier les changements de `USER`.

## ğŸ”¹ Pourquoi utiliser `WORKDIR` ?

* DÃ©finit le **rÃ©pertoire de travail par dÃ©faut** pour toutes les instructions suivantes (`RUN`, `CMD`, `ENTRYPOINT`, `COPY`, `ADD`).
* Ã‰vite les enchaÃ®nements de `cd â€¦ && â€¦` qui sont **illisibles et fragiles**.
* AmÃ©liore la lisibilitÃ© et la maintenance du Dockerfile.
* Rend le conteneur **plus prÃ©visible**.

***

## ğŸ”¹ Exemple simple

âŒ Mauvaise pratique sans `WORKDIR` :

```dockerfile
FROM python:3.12

RUN cd /app && pip install -r requirements.txt
COPY . /app
CMD ["python", "/app/main.py"]
```

ğŸ‘‰ ProblÃ¨mes :

* `cd` nâ€™est valide que dans cette **instruction RUN** (pas persistant).
* Peu lisible.
* Risque dâ€™erreurs si on oublie le `cd`.

***

âœ… Bonne pratique avec `WORKDIR` :

```dockerfile
FROM python:3.12

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .

CMD ["python", "main.py"]
```

ğŸ‘‰ Avantages :

* Plus clair, chaque Ã©tape sait quâ€™elle sâ€™exÃ©cute **dans `/app`**.
* Pas besoin de `cd`.
* Plus facile Ã  maintenir.

***

## ğŸ”¹ Points clÃ©s Ã  retenir

1.  Toujours utiliser des **chemins absolus** :

    ```dockerfile
    WORKDIR /usr/src/app
    ```

    et pas `WORKDIR src/app` (risque de confusion).
2.  On peut dÃ©finir **plusieurs `WORKDIR`** dans un Dockerfile.\
    Exemple :

    ```dockerfile
    WORKDIR /app
    RUN echo "fichier1" > f1.txt

    WORKDIR /data
    RUN echo "fichier2" > f2.txt
    ```

    â†’ Chaque `WORKDIR` dÃ©finit le **contexte pour les instructions suivantes**.
3. Si le rÃ©pertoire nâ€™existe pas, Docker le **crÃ©e automatiquement**.\
   Pas besoin de `RUN mkdir -p`.

***

## ğŸ”¹ Exemple combinÃ© (WORKDIR + USER)

Voici un exemple propre et sÃ©curisÃ© pour une appli Node.js :

```dockerfile
FROM node:20-alpine

# CrÃ©er un utilisateur non-root
RUN addgroup -S appgroup && adduser -S appuser -G appgroup

# DÃ©finir le rÃ©pertoire de travail
WORKDIR /usr/src/app

# Copier uniquement les fichiers nÃ©cessaires pour installer les deps
COPY package*.json ./

RUN npm install --production

# Copier le reste du code
COPY . .

# DÃ©finir lâ€™utilisateur non-root
USER appuser

# Lancer lâ€™app
CMD ["node", "server.js"]
```

ğŸ‘‰ Ici :

* `WORKDIR /usr/src/app` simplifie toutes les instructions suivantes.
* Pas besoin de `cd`.
* Lâ€™app tourne sous `appuser`.

## ğŸ”¹ Quâ€™est-ce que `ONBUILD` ?

* Câ€™est une **instruction diffÃ©rÃ©e**.
* Elle **ne sâ€™exÃ©cute pas** quand tu construis lâ€™image qui contient le `ONBUILD`.
* Elle **sâ€™exÃ©cute automatiquement** quand une autre image fait un `FROM cette_image`.

ğŸ‘‰ On peut voir Ã§a comme un **hook (crochet)** que tu poses dans lâ€™image parent, et qui sera dÃ©clenchÃ© dans lâ€™image enfant.

***

## ğŸ”¹ Exemple basique

**Image parent :**

```dockerfile
# syntax=docker/dockerfile:1
FROM node:20-alpine

# PrÃ©parer une instruction diffÃ©rÃ©e
ONBUILD COPY . /usr/src/app
ONBUILD WORKDIR /usr/src/app
ONBUILD RUN npm install

CMD ["node", "server.js"]
```

Quand tu construis cette image, les `ONBUILD` **ne sont pas exÃ©cutÃ©s**.\
Tu peux la tagger par exemple en `my-node-base:onbuild`.

***

**Image enfant :**

```dockerfile
FROM my-node-base:onbuild
```

ğŸ‘‰ Lors de la construction de cette image enfant :

* `COPY . /usr/src/app` est exÃ©cutÃ©
* `WORKDIR /usr/src/app` est exÃ©cutÃ©
* `RUN npm install` est exÃ©cutÃ©

Donc tu obtiens automatiquement une image avec ton code Node.js installÃ©, **sans rÃ©pÃ©ter les Ã©tapes**.

***

## ğŸ”¹ Cas dâ€™usage

* **Stacks de langage/framework** : Ruby, Node.js, Go, etc.\
  â†’ Ex : `ruby:onbuild` est une variante qui dÃ©clenche automatiquement un `bundle install` dans lâ€™image enfant.
* **Images gÃ©nÃ©riques pour bootstrapping** : tu fournis une base et imposes aux utilisateurs certaines Ã©tapes lors de lâ€™hÃ©ritage.

***

## ğŸ”¹ Bonnes pratiques

âœ… Utiliser un **tag sÃ©parÃ©** (`myimage:onbuild`) pour ne pas surprendre les utilisateurs qui hÃ©ritent sans le vouloir.\
âœ… Documenter clairement les comportements dÃ©clenchÃ©s.\
âš ï¸ Attention avec `COPY` ou `ADD` :

* Si lâ€™image enfant nâ€™a pas les fichiers attendus, la construction **Ã©choue brutalement**.\
  âš ï¸ Pas idÃ©al pour des images finales en prod, câ€™est plus adaptÃ© Ã  des **images de dev/gabarits**.

***

## ğŸ”¹ RÃ©sumÃ© visuel

ğŸ“Œ **Image parent** (prÃ©pare des instructions diffÃ©rÃ©es)

```
Dockerfile Parent  ----> construit ----> Image Parent (avec hooks ONBUILD)
```

ğŸ“Œ **Image enfant** (dÃ©clenche les hooks lors du build)

```
Dockerfile Enfant (FROM Parent) ----> ONBUILD sâ€™exÃ©cute ----> Image Enfant prÃªte
```
